{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-55nRqcMJNVo","executionInfo":{"status":"ok","timestamp":1700693448060,"user_tz":-540,"elapsed":347254,"user":{"displayName":"Oakyoung Han","userId":"01975750084907398472"}},"outputId":"52304d66-6a8f-43f9-de07-60d57062f242"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 121ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 0, State: [[-0.03159326  0.21373169 -0.00829929 -0.2614124 ]], Action: 1, Reward: 1.0, Next State: [[-0.03159326  0.21373169 -0.00829929 -0.2614124 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 0, State: [[-0.02731862  0.40897113 -0.01352754 -0.5567014 ]], Action: 1, Reward: 1.0, Next State: [[-0.02731862  0.40897113 -0.01352754 -0.5567014 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 0, State: [[-0.0191392   0.60428035 -0.02466157 -0.85361546]], Action: 1, Reward: 1.0, Next State: [[-0.0191392   0.60428035 -0.02466157 -0.85361546]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 0, State: [[-0.0070536   0.79972965 -0.04173388 -1.15395   ]], Action: 1, Reward: 1.0, Next State: [[-0.0070536   0.79972965 -0.04173388 -1.15395   ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 0, State: [[ 0.008941    0.99537027 -0.06481288 -1.4594216 ]], Action: 1, Reward: 1.0, Next State: [[ 0.008941    0.99537027 -0.06481288 -1.4594216 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 0, State: [[ 0.0288484   1.1912245  -0.09400131 -1.7716277 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0288484   1.1912245  -0.09400131 -1.7716277 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 0, State: [[ 0.05267289  1.3872728  -0.12943387 -2.0919976 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05267289  1.3872728  -0.12943387 -2.0919976 ]], Done: False\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 0, State: [[ 0.08041835  1.5834401  -0.17127381 -2.4217346 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08041835  1.5834401  -0.17127381 -2.4217346 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 0, State: [[ 0.11208715  1.7795786  -0.21970852 -2.7617462 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11208715  1.7795786  -0.21970852 -2.7617462 ]], Done: True\n","Episode: 0, Total Reward: 9.0\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 1, State: [[ 0.00511212  0.16557303  0.00928918 -0.3144844 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00511212  0.16557303  0.00928918 -0.3144844 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 1, State: [[ 0.00842358  0.36056143  0.00299949 -0.60422343]], Action: 1, Reward: 1.0, Next State: [[ 0.00842358  0.36056143  0.00299949 -0.60422343]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 1, State: [[ 0.01563481  0.5556413  -0.00908498 -0.89596003]], Action: 1, Reward: 1.0, Next State: [[ 0.01563481  0.5556413  -0.00908498 -0.89596003]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 1, State: [[ 0.02674764  0.75088525 -0.02700418 -1.1914848 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02674764  0.75088525 -0.02700418 -1.1914848 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 1, State: [[ 0.04176534  0.94634646 -0.05083388 -1.492508  ]], Action: 1, Reward: 1.0, Next State: [[ 0.04176534  0.94634646 -0.05083388 -1.492508  ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 1, State: [[ 0.06069227  1.1420488  -0.08068404 -1.800621  ]], Action: 1, Reward: 1.0, Next State: [[ 0.06069227  1.1420488  -0.08068404 -1.800621  ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 1, State: [[ 0.08353325  1.3379748  -0.11669645 -2.1172493 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08353325  1.3379748  -0.11669645 -2.1172493 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 1, State: [[ 0.11029275  1.5340515  -0.15904145 -2.443595  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11029275  1.5340515  -0.15904145 -2.443595  ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 1, State: [[ 0.14097378  1.7301337  -0.20791334 -2.7805674 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14097378  1.7301337  -0.20791334 -2.7805674 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 1, State: [[ 0.17557645  1.9259845  -0.26352468 -3.128704  ]], Action: 1, Reward: 1.0, Next State: [[ 0.17557645  1.9259845  -0.26352468 -3.128704  ]], Done: True\n","Episode: 1, Total Reward: 10.0\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 2, State: [[ 0.0351273   0.16271442  0.03169854 -0.29160094]], Action: 1, Reward: 1.0, Next State: [[ 0.0351273   0.16271442  0.03169854 -0.29160094]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 2, State: [[ 0.0383816   0.3573704   0.02586653 -0.5741204 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0383816   0.3573704   0.02586653 -0.5741204 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 2, State: [[ 0.045529    0.5521203   0.01438412 -0.8585437 ]], Action: 1, Reward: 1.0, Next State: [[ 0.045529    0.5521203   0.01438412 -0.8585437 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 2, State: [[ 0.05657141  0.74704343 -0.00278676 -1.1466693 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05657141  0.74704343 -0.00278676 -1.1466693 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 2, State: [[ 0.07151227  0.9422017  -0.02572014 -1.4402248 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07151227  0.9422017  -0.02572014 -1.4402248 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 2, State: [[ 0.09035631  1.1376308  -0.05452464 -1.7408324 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09035631  1.1376308  -0.05452464 -1.7408324 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 2, State: [[ 0.11310893  1.3333296  -0.08934129 -2.0499666 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11310893  1.3333296  -0.08934129 -2.0499666 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 2, State: [[ 0.13977551  1.529246   -0.13034062 -2.3689008 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13977551  1.529246   -0.13034062 -2.3689008 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 2, State: [[ 0.17036043  1.7252623  -0.17771864 -2.6986427 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17036043  1.7252623  -0.17771864 -2.6986427 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 2, State: [[ 0.20486568  1.9211756  -0.2316915  -3.0398588 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20486568  1.9211756  -0.2316915  -3.0398588 ]], Done: True\n","Episode: 2, Total Reward: 10.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 3, State: [[-0.04550136  0.15880404  0.02916429 -0.23764932]], Action: 1, Reward: 1.0, Next State: [[-0.04550136  0.15880404  0.02916429 -0.23764932]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 3, State: [[-0.04232528  0.35349748  0.0244113  -0.52099216]], Action: 1, Reward: 1.0, Next State: [[-0.04232528  0.35349748  0.0244113  -0.52099216]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 3, State: [[-0.03525533  0.5482674   0.01399146 -0.8058839 ]], Action: 1, Reward: 1.0, Next State: [[-0.03525533  0.5482674   0.01399146 -0.8058839 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 3, State: [[-0.02428998  0.7431948  -0.00212622 -1.094133  ]], Action: 1, Reward: 1.0, Next State: [[-0.02428998  0.7431948  -0.00212622 -1.094133  ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 3, State: [[-0.00942609  0.9383447  -0.02400888 -1.3874823 ]], Action: 1, Reward: 1.0, Next State: [[-0.00942609  0.9383447  -0.02400888 -1.3874823 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 3, State: [[ 0.00934081  1.1337576  -0.05175853 -1.687575  ]], Action: 1, Reward: 1.0, Next State: [[ 0.00934081  1.1337576  -0.05175853 -1.687575  ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 3, State: [[ 0.03201596  1.3294384  -0.08551002 -1.9959134 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03201596  1.3294384  -0.08551002 -1.9959134 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 3, State: [[ 0.05860473  1.5253443  -0.12542829 -2.3138077 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05860473  1.5253443  -0.12542829 -2.3138077 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 3, State: [[ 0.08911161  1.7213683  -0.17170444 -2.6423132 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08911161  1.7213683  -0.17170444 -2.6423132 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 3, State: [[ 0.12353898  1.9173223  -0.22455071 -2.9821553 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12353898  1.9173223  -0.22455071 -2.9821553 ]], Done: True\n","Episode: 3, Total Reward: 10.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 4, State: [[-0.01916976  0.20794274 -0.04281438 -0.29697406]], Action: 1, Reward: 1.0, Next State: [[-0.01916976  0.20794274 -0.04281438 -0.29697406]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 4, State: [[-0.0150109   0.40364805 -0.04875386 -0.6028466 ]], Action: 1, Reward: 1.0, Next State: [[-0.0150109   0.40364805 -0.04875386 -0.6028466 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 4, State: [[-0.00693794  0.5994168  -0.06081079 -0.9104788 ]], Action: 1, Reward: 1.0, Next State: [[-0.00693794  0.5994168  -0.06081079 -0.9104788 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 4, State: [[ 0.0050504   0.7953066  -0.07902037 -1.2216377 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0050504   0.7953066  -0.07902037 -1.2216377 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 4, State: [[ 0.02095653  0.9913528  -0.10345312 -1.5379971 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02095653  0.9913528  -0.10345312 -1.5379971 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 4, State: [[ 0.04078358  1.1875565  -0.13421306 -1.8610902 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04078358  1.1875565  -0.13421306 -1.8610902 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 4, State: [[ 0.06453472  1.3838708  -0.17143486 -2.1922538 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06453472  1.3838708  -0.17143486 -2.1922538 ]], Done: False\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 4, State: [[ 0.09221213  1.5801855  -0.21527995 -2.5325646 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09221213  1.5801855  -0.21527995 -2.5325646 ]], Done: True\n","Episode: 4, Total Reward: 8.0\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 5, State: [[ 0.02131976  0.16971105  0.01006351 -0.32743135]], Action: 1, Reward: 1.0, Next State: [[ 0.02131976  0.16971105  0.01006351 -0.32743135]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 5, State: [[ 0.02471398  0.36468828  0.00351489 -0.61692375]], Action: 1, Reward: 1.0, Next State: [[ 0.02471398  0.36468828  0.00351489 -0.61692375]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 5, State: [[ 0.03200774  0.559761   -0.00882359 -0.9084976 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03200774  0.559761   -0.00882359 -0.9084976 ]], Done: False\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 5, State: [[ 0.04320296  0.75500125 -0.02699354 -1.2039407 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04320296  0.75500125 -0.02699354 -1.2039407 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 5, State: [[ 0.05830299  0.95046157 -0.05107236 -1.5049595 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05830299  0.95046157 -0.05107236 -1.5049595 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 5, State: [[ 0.07731222  1.1461645  -0.08117154 -1.81314   ]], Action: 1, Reward: 1.0, Next State: [[ 0.07731222  1.1461645  -0.08117154 -1.81314   ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 5, State: [[ 0.10023551  1.3420912  -0.11743435 -2.1299005 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10023551  1.3420912  -0.11743435 -2.1299005 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 5, State: [[ 0.12707733  1.5381664  -0.16003236 -2.456434  ]], Action: 1, Reward: 1.0, Next State: [[ 0.12707733  1.5381664  -0.16003236 -2.456434  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 5, State: [[ 0.15784065  1.7342421  -0.20916103 -2.7936382 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15784065  1.7342421  -0.20916103 -2.7936382 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 5, State: [[ 0.1925255  1.9300781 -0.2650338 -3.1420362]], Action: 1, Reward: 1.0, Next State: [[ 0.1925255  1.9300781 -0.2650338 -3.1420362]], Done: True\n","Episode: 5, Total Reward: 10.0\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 6, State: [[ 0.0476825   0.1594506  -0.04191669 -0.2846412 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0476825   0.1594506  -0.04191669 -0.2846412 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 6, State: [[ 0.05087151  0.35514453 -0.04760952 -0.5902442 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05087151  0.35514453 -0.04760952 -0.5902442 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 6, State: [[ 0.0579744  0.5508996 -0.0594144 -0.897536 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0579744  0.5508996 -0.0594144 -0.897536 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 6, State: [[ 0.0689924   0.7467745  -0.07736512 -1.2082874 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0689924   0.7467745  -0.07736512 -1.2082874 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 6, State: [[ 0.08392788  0.94280577 -0.10153087 -1.5241774 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08392788  0.94280577 -0.10153087 -1.5241774 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 6, State: [[ 0.102784    1.1389966  -0.13201442 -1.846747  ]], Action: 1, Reward: 1.0, Next State: [[ 0.102784    1.1389966  -0.13201442 -1.846747  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 6, State: [[ 0.12556393  1.3353031  -0.16894937 -2.177344  ]], Action: 1, Reward: 1.0, Next State: [[ 0.12556393  1.3353031  -0.16894937 -2.177344  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 6, State: [[ 0.15226999  1.5316184  -0.21249624 -2.5170593 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15226999  1.5316184  -0.21249624 -2.5170593 ]], Done: True\n","Episode: 6, Total Reward: 8.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 7, State: [[ 0.0086476   0.19043818 -0.01441081 -0.2689835 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0086476   0.19043818 -0.01441081 -0.2689835 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 7, State: [[ 0.01245636  0.38576278 -0.01979048 -0.56617665]], Action: 1, Reward: 1.0, Next State: [[ 0.01245636  0.38576278 -0.01979048 -0.56617665]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 7, State: [[ 0.02017162  0.58115673 -0.03111401 -0.86502814]], Action: 1, Reward: 1.0, Next State: [[ 0.02017162  0.58115673 -0.03111401 -0.86502814]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 7, State: [[ 0.03179475  0.77668804 -0.04841457 -1.1673292 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03179475  0.77668804 -0.04841457 -1.1673292 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 7, State: [[ 0.04732851  0.9724054  -0.07176116 -1.4747895 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04732851  0.9724054  -0.07176116 -1.4747895 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 7, State: [[ 0.06677662  1.1683271  -0.10125695 -1.7889955 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06677662  1.1683271  -0.10125695 -1.7889955 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 7, State: [[ 0.09014316  1.3644291  -0.13703686 -2.1113603 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09014316  1.3644291  -0.13703686 -2.1113603 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 7, State: [[ 0.11743174  1.5606297  -0.17926407 -2.4430654 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11743174  1.5606297  -0.17926407 -2.4430654 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 7, State: [[ 0.14864434  1.7567734  -0.22812538 -2.7849877 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14864434  1.7567734  -0.22812538 -2.7849877 ]], Done: True\n","Episode: 7, Total Reward: 9.0\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 8, State: [[-0.00462915  0.20866446  0.04529434 -0.3010468 ]], Action: 1, Reward: 1.0, Next State: [[-0.00462915  0.20866446  0.04529434 -0.3010468 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 8, State: [[-4.5585612e-04  4.0311256e-01  3.9273407e-02 -5.7910776e-01]], Action: 1, Reward: 1.0, Next State: [[-4.5585612e-04  4.0311256e-01  3.9273407e-02 -5.7910776e-01]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 8, State: [[ 0.0076064   0.59766275  0.02769125 -0.85916466]], Action: 1, Reward: 1.0, Next State: [[ 0.0076064   0.59766275  0.02769125 -0.85916466]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 8, State: [[ 0.01955965  0.7923968   0.01050796 -1.1430135 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01955965  0.7923968   0.01050796 -1.1430135 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 8, State: [[ 0.03540758  0.98737985 -0.01235231 -1.4323827 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03540758  0.98737985 -0.01235231 -1.4323827 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 8, State: [[ 0.05515518  1.182652   -0.04099996 -1.7289001 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05515518  1.182652   -0.04099996 -1.7289001 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 8, State: [[ 0.07880823  1.3782178  -0.07557797 -2.0340528 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07880823  1.3782178  -0.07557797 -2.0340528 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 8, State: [[ 0.10637258  1.574033   -0.11625902 -2.3491359 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10637258  1.574033   -0.11625902 -2.3491359 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 8, State: [[ 0.13785324  1.7699898  -0.16324174 -2.6751902 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13785324  1.7699898  -0.16324174 -2.6751902 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 8, State: [[ 0.17325303  1.9658983  -0.21674554 -3.0129263 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17325303  1.9658983  -0.21674554 -3.0129263 ]], Done: True\n","Episode: 8, Total Reward: 10.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 9, State: [[-5.6485787e-05  2.2769471e-01  3.6471587e-02 -2.5422046e-01]], Action: 1, Reward: 1.0, Next State: [[-5.6485787e-05  2.2769471e-01  3.6471587e-02 -2.5422046e-01]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 9, State: [[ 0.00449741  0.42227742  0.03138718 -0.53518015]], Action: 1, Reward: 1.0, Next State: [[ 0.00449741  0.42227742  0.03138718 -0.53518015]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 9, State: [[ 0.01294296  0.61694425  0.02068358 -0.8178103 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01294296  0.61694425  0.02068358 -0.8178103 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 9, State: [[ 0.02528184  0.81177706  0.00432737 -1.1039165 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02528184  0.81177706  0.00432737 -1.1039165 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 9, State: [[ 0.04151738  1.0068419  -0.01775096 -1.3952386 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04151738  1.0068419  -0.01775096 -1.3952386 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 9, State: [[ 0.06165422  1.2021801  -0.04565573 -1.6934184 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06165422  1.2021801  -0.04565573 -1.6934184 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 9, State: [[ 0.08569782  1.3977984  -0.0795241  -1.9999582 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08569782  1.3977984  -0.0795241  -1.9999582 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 9, State: [[ 0.11365379  1.5936556  -0.11952326 -2.316171  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11365379  1.5936556  -0.11952326 -2.316171  ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 9, State: [[ 0.1455269   1.7896475  -0.16584669 -2.6431174 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1455269   1.7896475  -0.16584669 -2.6431174 ]], Done: False\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 9, State: [[ 0.18131985  1.9855886  -0.21870904 -2.981532  ]], Action: 1, Reward: 1.0, Next State: [[ 0.18131985  1.9855886  -0.21870904 -2.981532  ]], Done: True\n","Episode: 9, Total Reward: 10.0\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 10, State: [[ 2.3037482e-02  2.1470487e-01  8.1307888e-05 -3.0777150e-01]], Action: 1, Reward: 1.0, Next State: [[ 2.3037482e-02  2.1470487e-01  8.1307888e-05 -3.0777150e-01]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 10, State: [[ 0.02733158  0.40982565 -0.00607412 -0.60042876]], Action: 1, Reward: 1.0, Next State: [[ 0.02733158  0.40982565 -0.00607412 -0.60042876]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 10, State: [[ 0.03552809  0.6050321  -0.0180827  -0.89501876]], Action: 1, Reward: 1.0, Next State: [[ 0.03552809  0.6050321  -0.0180827  -0.89501876]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 10, State: [[ 0.04762873  0.8003945  -0.03598307 -1.1933305 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04762873  0.8003945  -0.03598307 -1.1933305 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 10, State: [[ 0.06363662  0.9959635  -0.05984968 -1.4970709 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06363662  0.9959635  -0.05984968 -1.4970709 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 10, State: [[ 0.08355589  1.1917597  -0.0897911  -1.8078247 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08355589  1.1917597  -0.0897911  -1.8078247 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 10, State: [[ 0.10739109  1.3877612  -0.1259476  -2.1270058 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10739109  1.3877612  -0.1259476  -2.1270058 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 10, State: [[ 0.13514632  1.5838896  -0.16848771 -2.4557986 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13514632  1.5838896  -0.16848771 -2.4557986 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 10, State: [[ 0.1668241   1.7799922  -0.21760368 -2.7950885 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1668241   1.7799922  -0.21760368 -2.7950885 ]], Done: True\n","Episode: 10, Total Reward: 9.0\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 11, State: [[-0.01795824  0.22407739  0.00366111 -0.3030533 ]], Action: 1, Reward: 1.0, Next State: [[-0.01795824  0.22407739  0.00366111 -0.3030533 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 11, State: [[-0.01347669  0.41914698 -0.00239995 -0.59457934]], Action: 1, Reward: 1.0, Next State: [[-0.01347669  0.41914698 -0.00239995 -0.59457934]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 11, State: [[-0.00509375  0.61430246 -0.01429154 -0.8880173 ]], Action: 1, Reward: 1.0, Next State: [[-0.00509375  0.61430246 -0.01429154 -0.8880173 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 11, State: [[ 0.0071923   0.80961543 -0.03205189 -1.1851584 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0071923   0.80961543 -0.03205189 -1.1851584 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 11, State: [[ 0.02338461  1.0051382  -0.05575505 -1.4877135 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02338461  1.0051382  -0.05575505 -1.4877135 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 11, State: [[ 0.04348737  1.2008932  -0.08550932 -1.7972733 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04348737  1.2008932  -0.08550932 -1.7972733 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 11, State: [[ 0.06750523  1.3968618  -0.12145479 -2.1152613 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06750523  1.3968618  -0.12145479 -2.1152613 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 11, State: [[ 0.09544247  1.592969   -0.16376002 -2.4428751 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09544247  1.592969   -0.16376002 -2.4428751 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 11, State: [[ 0.12730184  1.7890671  -0.21261752 -2.7810175 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12730184  1.7890671  -0.21261752 -2.7810175 ]], Done: True\n","Episode: 11, Total Reward: 9.0\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 12, State: [[ 0.01476127  0.22755085  0.03926317 -0.3224253 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01476127  0.22755085  0.03926317 -0.3224253 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 12, State: [[ 0.01931229  0.42209232  0.03281466 -0.60247225]], Action: 1, Reward: 1.0, Next State: [[ 0.01931229  0.42209232  0.03281466 -0.60247225]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 12, State: [[ 0.02775413  0.6167403   0.02076522 -0.88464123]], Action: 1, Reward: 1.0, Next State: [[ 0.02775413  0.6167403   0.02076522 -0.88464123]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 12, State: [[ 0.04008894  0.8115742   0.00307239 -1.1707246 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04008894  0.8115742   0.00307239 -1.1707246 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 12, State: [[ 0.05632043  1.006656   -0.0203421  -1.4624428 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05632043  1.006656   -0.0203421  -1.4624428 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 12, State: [[ 0.07645354  1.2020214  -0.04959095 -1.7614101 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07645354  1.2020214  -0.04959095 -1.7614101 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 12, State: [[ 0.10049397  1.3976681  -0.08481915 -2.0690932 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10049397  1.3976681  -0.08481915 -2.0690932 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 12, State: [[ 0.12844734  1.593544   -0.12620102 -2.3867576 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12844734  1.593544   -0.12620102 -2.3867576 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 12, State: [[ 0.16031821  1.7895299  -0.17393617 -2.7154036 ]], Action: 1, Reward: 1.0, Next State: [[ 0.16031821  1.7895299  -0.17393617 -2.7154036 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 12, State: [[ 0.19610882  1.9854221  -0.22824425 -3.055688  ]], Action: 1, Reward: 1.0, Next State: [[ 0.19610882  1.9854221  -0.22824425 -3.055688  ]], Done: True\n","Episode: 12, Total Reward: 10.0\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 13, State: [[ 0.01583692  0.16324432  0.02596723 -0.24958298]], Action: 1, Reward: 1.0, Next State: [[ 0.01583692  0.16324432  0.02596723 -0.24958298]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 13, State: [[ 0.0191018   0.357986    0.02097557 -0.5339635 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0191018   0.357986    0.02097557 -0.5339635 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 13, State: [[ 0.02626153  0.5528068   0.0102963  -0.81996405]], Action: 1, Reward: 1.0, Next State: [[ 0.02626153  0.5528068   0.0102963  -0.81996405]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 13, State: [[ 0.03731766  0.74778634 -0.00610299 -1.1093907 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03731766  0.74778634 -0.00610299 -1.1093907 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 13, State: [[ 0.05227339  0.9429879  -0.0282908  -1.403982  ]], Action: 1, Reward: 1.0, Next State: [[ 0.05227339  0.9429879  -0.0282908  -1.403982  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 13, State: [[ 0.07113314  1.1384495  -0.05637044 -1.7053735 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07113314  1.1384495  -0.05637044 -1.7053735 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 13, State: [[ 0.09390214  1.334173   -0.09047791 -2.0150564 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09390214  1.334173   -0.09047791 -2.0150564 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 13, State: [[ 0.1205856   1.5301104  -0.13077904 -2.3343246 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1205856   1.5301104  -0.13077904 -2.3343246 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 13, State: [[ 0.1511878   1.7261494  -0.17746553 -2.6642115 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1511878   1.7261494  -0.17746553 -2.6642115 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 13, State: [[ 0.18571079  1.9220941  -0.23074977 -3.0054138 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18571079  1.9220941  -0.23074977 -3.0054138 ]], Done: True\n","Episode: 13, Total Reward: 10.0\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 14, State: [[ 0.0037659  0.2422539 -0.0283211 -0.3496187]], Action: 1, Reward: 1.0, Next State: [[ 0.0037659  0.2422539 -0.0283211 -0.3496187]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 14, State: [[ 0.00861098  0.43776694 -0.03531348 -0.651096  ]], Action: 1, Reward: 1.0, Next State: [[ 0.00861098  0.43776694 -0.03531348 -0.651096  ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 14, State: [[ 0.01736632  0.6333625  -0.0483354  -0.95468634]], Action: 1, Reward: 1.0, Next State: [[ 0.01736632  0.6333625  -0.0483354  -0.95468634]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 14, State: [[ 0.03003357  0.82910013 -0.06742913 -1.262155  ]], Action: 1, Reward: 1.0, Next State: [[ 0.03003357  0.82910013 -0.06742913 -1.262155  ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 14, State: [[ 0.04661557  1.0250164  -0.09267222 -1.5751708 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04661557  1.0250164  -0.09267222 -1.5751708 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 14, State: [[ 0.0671159   1.221113   -0.12417564 -1.89526   ]], Action: 1, Reward: 1.0, Next State: [[ 0.0671159   1.221113   -0.12417564 -1.89526   ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 14, State: [[ 0.09153815  1.4173431  -0.16208084 -2.2237527 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09153815  1.4173431  -0.16208084 -2.2237527 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 14, State: [[ 0.11988502  1.6135967  -0.20655589 -2.5617182 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11988502  1.6135967  -0.20655589 -2.5617182 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 14, State: [[ 0.15215695  1.8096808  -0.25779027 -2.9098887 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15215695  1.8096808  -0.25779027 -2.9098887 ]], Done: True\n","Episode: 14, Total Reward: 9.0\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 15, State: [[-0.04809962  0.23183922 -0.04405398 -0.2738799 ]], Action: 1, Reward: 1.0, Next State: [[-0.04809962  0.23183922 -0.04405398 -0.2738799 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 15, State: [[-0.04346284  0.42756116 -0.04953158 -0.58012563]], Action: 1, Reward: 1.0, Next State: [[-0.04346284  0.42756116 -0.04953158 -0.58012563]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 15, State: [[-0.03491161  0.6233409  -0.06113409 -0.8879914 ]], Action: 1, Reward: 1.0, Next State: [[-0.03491161  0.6233409  -0.06113409 -0.8879914 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 15, State: [[-0.02244479  0.81923693 -0.07889392 -1.1992488 ]], Action: 1, Reward: 1.0, Next State: [[-0.02244479  0.81923693 -0.07889392 -1.1992488 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 15, State: [[-0.00606005  1.015286   -0.1028789  -1.5155784 ]], Action: 1, Reward: 1.0, Next State: [[-0.00606005  1.015286   -0.1028789  -1.5155784 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 15, State: [[ 0.01424567  1.2114915  -0.13319047 -1.8385235 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01424567  1.2114915  -0.13319047 -1.8385235 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 15, State: [[ 0.03847549  1.4078097  -0.16996093 -2.1694353 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03847549  1.4078097  -0.16996093 -2.1694353 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 15, State: [[ 0.06663169  1.6041349  -0.21334964 -2.509408  ]], Action: 1, Reward: 1.0, Next State: [[ 0.06663169  1.6041349  -0.21334964 -2.509408  ]], Done: True\n","Episode: 15, Total Reward: 8.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 16, State: [[-0.02062677  0.18705873  0.01102978 -0.24665318]], Action: 1, Reward: 1.0, Next State: [[-0.02062677  0.18705873  0.01102978 -0.24665318]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 16, State: [[-0.01688559  0.38202143  0.00609671 -0.53583676]], Action: 1, Reward: 1.0, Next State: [[-0.01688559  0.38202143  0.00609671 -0.53583676]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 16, State: [[-0.00924517  0.5770571  -0.00462002 -0.82659245]], Action: 1, Reward: 1.0, Next State: [[-0.00924517  0.5770571  -0.00462002 -0.82659245]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 16, State: [[ 0.00229598  0.77224195 -0.02115187 -1.1207248 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00229598  0.77224195 -0.02115187 -1.1207248 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 16, State: [[ 0.01774082  0.96763486 -0.04356637 -1.4199668 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01774082  0.96763486 -0.04356637 -1.4199668 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 16, State: [[ 0.03709351  1.163268   -0.0719657  -1.7259425 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03709351  1.163268   -0.0719657  -1.7259425 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 16, State: [[ 0.06035887  1.3591354  -0.10648455 -2.0401227 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06035887  1.3591354  -0.10648455 -2.0401227 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 16, State: [[ 0.08754158  1.5551794  -0.14728701 -2.3637705 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08754158  1.5551794  -0.14728701 -2.3637705 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 16, State: [[ 0.11864517  1.7512742  -0.19456242 -2.697874  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11864517  1.7512742  -0.19456242 -2.697874  ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 16, State: [[ 0.15367065  1.9472078  -0.2485199  -3.0430703 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15367065  1.9472078  -0.2485199  -3.0430703 ]], Done: True\n","Episode: 16, Total Reward: 10.0\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 17, State: [[-0.00855119  0.16798005  0.00297952 -0.315866  ]], Action: 1, Reward: 1.0, Next State: [[-0.00855119  0.16798005  0.00297952 -0.315866  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 17, State: [[-0.00519159  0.36305943 -0.0033378  -0.6076078 ]], Action: 1, Reward: 1.0, Next State: [[-0.00519159  0.36305943 -0.0033378  -0.6076078 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 17, State: [[ 0.0020696   0.5582279  -0.01548995 -0.9013402 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0020696   0.5582279  -0.01548995 -0.9013402 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 17, State: [[ 0.01323416  0.75355625 -0.03351676 -1.1988515 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01323416  0.75355625 -0.03351676 -1.1988515 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 17, State: [[ 0.02830528  0.9490954  -0.05749379 -1.5018476 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02830528  0.9490954  -0.05749379 -1.5018476 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 17, State: [[ 0.04728719  1.1448663  -0.08753074 -1.8119127 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04728719  1.1448663  -0.08753074 -1.8119127 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 17, State: [[ 0.07018452  1.3408477  -0.12376899 -2.1304603 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07018452  1.3408477  -0.12376899 -2.1304603 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 17, State: [[ 0.09700147  1.5369612  -0.1663782  -2.4586756 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09700147  1.5369612  -0.1663782  -2.4586756 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 17, State: [[ 0.1277407  1.7330552 -0.2155517 -2.7974446]], Action: 1, Reward: 1.0, Next State: [[ 0.1277407  1.7330552 -0.2155517 -2.7974446]], Done: True\n","Episode: 17, Total Reward: 9.0\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 18, State: [[ 0.03146306  0.19896016  0.02796707 -0.25724405]], Action: 1, Reward: 1.0, Next State: [[ 0.03146306  0.19896016  0.02796707 -0.25724405]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 18, State: [[ 0.03544226  0.3936719   0.02282219 -0.5409762 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03544226  0.3936719   0.02282219 -0.5409762 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 18, State: [[ 0.0433157   0.58846575  0.01200266 -0.82638174]], Action: 1, Reward: 1.0, Next State: [[ 0.0433157   0.58846575  0.01200266 -0.82638174]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 18, State: [[ 0.05508501  0.7834215  -0.00452497 -1.1152656 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05508501  0.7834215  -0.00452497 -1.1152656 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 18, State: [[ 0.07075344  0.9786026  -0.02683029 -1.4093646 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07075344  0.9786026  -0.02683029 -1.4093646 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 18, State: [[ 0.0903255   1.1740469  -0.05501758 -1.7103126 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0903255   1.1740469  -0.05501758 -1.7103126 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 18, State: [[ 0.11380643  1.369756   -0.08922383 -2.0195992 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11380643  1.369756   -0.08922383 -2.0195992 ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 18, State: [[ 0.14120156  1.5656824  -0.12961581 -2.3385167 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14120156  1.5656824  -0.12961581 -2.3385167 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 18, State: [[ 0.1725152   1.7617133  -0.17638615 -2.6680968 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1725152   1.7617133  -0.17638615 -2.6680968 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 18, State: [[ 0.20774946  1.9576526  -0.22974809 -3.0090346 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20774946  1.9576526  -0.22974809 -3.0090346 ]], Done: True\n","Episode: 18, Total Reward: 10.0\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 19, State: [[-0.00089443  0.19967514 -0.01476749 -0.24953853]], Action: 1, Reward: 1.0, Next State: [[-0.00089443  0.19967514 -0.01476749 -0.24953853]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 19, State: [[ 0.00309908  0.39500484 -0.01975826 -0.5468426 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00309908  0.39500484 -0.01975826 -0.5468426 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 19, State: [[ 0.01099917  0.5903987  -0.03069511 -0.84568477]], Action: 1, Reward: 1.0, Next State: [[ 0.01099917  0.5903987  -0.03069511 -0.84568477]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 19, State: [[ 0.02280715  0.78592575 -0.04760881 -1.14786   ]], Action: 1, Reward: 1.0, Next State: [[ 0.02280715  0.78592575 -0.04760881 -1.14786   ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 49ms/step\n","Episode: 19, State: [[ 0.03852566  0.9816358  -0.07056601 -1.4550843 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03852566  0.9816358  -0.07056601 -1.4550843 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 19, State: [[ 0.05815838  1.1775495  -0.0996677  -1.7689526 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05815838  1.1775495  -0.0996677  -1.7689526 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 19, State: [[ 0.08170937  1.3736455  -0.13504675 -2.090891  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08170937  1.3736455  -0.13504675 -2.090891  ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 19, State: [[ 0.10918228  1.5698464  -0.17686456 -2.4220955 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10918228  1.5698464  -0.17686456 -2.4220955 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 19, State: [[ 0.14057921  1.7660009  -0.22530648 -2.763465  ]], Action: 1, Reward: 1.0, Next State: [[ 0.14057921  1.7660009  -0.22530648 -2.763465  ]], Done: True\n","Episode: 19, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 20, State: [[-0.03356875  0.24053228  0.04431517 -0.32519907]], Action: 1, Reward: 1.0, Next State: [[-0.03356875  0.24053228  0.04431517 -0.32519907]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 20, State: [[-0.0287581   0.43499616  0.03781118 -0.6035841 ]], Action: 1, Reward: 1.0, Next State: [[-0.0287581   0.43499616  0.03781118 -0.6035841 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 20, State: [[-0.02005818  0.6295695   0.0257395  -0.8841216 ]], Action: 1, Reward: 1.0, Next State: [[-0.02005818  0.6295695   0.0257395  -0.8841216 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 20, State: [[-0.00746679  0.8243326   0.00805707 -1.168603  ]], Action: 1, Reward: 1.0, Next State: [[-0.00746679  0.8243326   0.00805707 -1.168603  ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 20, State: [[ 0.00901986  1.0193489  -0.01531499 -1.458749  ]], Action: 1, Reward: 1.0, Next State: [[ 0.00901986  1.0193489  -0.01531499 -1.458749  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 20, State: [[ 0.02940684  1.2146553  -0.04448997 -1.7561767 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02940684  1.2146553  -0.04448997 -1.7561767 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 20, State: [[ 0.05369994  1.4102522  -0.07961351 -2.0623577 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05369994  1.4102522  -0.07961351 -2.0623577 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 20, State: [[ 0.08190499  1.6060905  -0.12086066 -2.3785663 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08190499  1.6060905  -0.12086066 -2.3785663 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 20, State: [[ 0.1140268   1.802055   -0.16843198 -2.7058153 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1140268   1.802055   -0.16843198 -2.7058153 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 20, State: [[ 0.1500679   1.997947   -0.22254829 -3.0447803 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1500679   1.997947   -0.22254829 -3.0447803 ]], Done: True\n","Episode: 20, Total Reward: 10.0\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 21, State: [[ 0.03614311  0.16858594  0.01034921 -0.26000193]], Action: 1, Reward: 1.0, Next State: [[ 0.03614311  0.16858594  0.01034921 -0.26000193]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 21, State: [[ 0.03951483  0.36355862  0.00514917 -0.5494027 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03951483  0.36355862  0.00514917 -0.5494027 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 21, State: [[ 0.046786    0.5586079  -0.00583888 -0.8404588 ]], Action: 1, Reward: 1.0, Next State: [[ 0.046786    0.5586079  -0.00583888 -0.8404588 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 21, State: [[ 0.05795816  0.75380903 -0.02264806 -1.1349722 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05795816  0.75380903 -0.02264806 -1.1349722 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 21, State: [[ 0.07303434  0.9492199  -0.04534751 -1.4346713 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07303434  0.9492199  -0.04534751 -1.4346713 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 21, State: [[ 0.09201874  1.1448709  -0.07404093 -1.7411736 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09201874  1.1448709  -0.07404093 -1.7411736 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 21, State: [[ 0.11491615  1.3407536  -0.1088644  -2.0559409 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11491615  1.3407536  -0.1088644  -2.0559409 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 21, State: [[ 0.14173123  1.5368071  -0.14998323 -2.3802233 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14173123  1.5368071  -0.14998323 -2.3802233 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 21, State: [[ 0.17246737  1.7329017  -0.19758768 -2.7149928 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17246737  1.7329017  -0.19758768 -2.7149928 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 21, State: [[ 0.2071254   1.92882    -0.25188753 -3.0608659 ]], Action: 1, Reward: 1.0, Next State: [[ 0.2071254   1.92882    -0.25188753 -3.0608659 ]], Done: True\n","Episode: 21, Total Reward: 10.0\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 22, State: [[-0.04487589  0.19216359 -0.01755742 -0.32404584]], Action: 1, Reward: 1.0, Next State: [[-0.04487589  0.19216359 -0.01755742 -0.32404584]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 22, State: [[-0.04103262  0.38753107 -0.02403834 -0.62221354]], Action: 1, Reward: 1.0, Next State: [[-0.04103262  0.38753107 -0.02403834 -0.62221354]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 22, State: [[-0.03328199  0.5829803  -0.03648261 -0.92236924]], Action: 1, Reward: 1.0, Next State: [[-0.03328199  0.5829803  -0.03648261 -0.92236924]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 22, State: [[-0.02162239  0.77857566 -0.05492999 -1.2262906 ]], Action: 1, Reward: 1.0, Next State: [[-0.02162239  0.77857566 -0.05492999 -1.2262906 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 22, State: [[-0.00605088  0.9743601  -0.0794558  -1.5356655 ]], Action: 1, Reward: 1.0, Next State: [[-0.00605088  0.9743601  -0.0794558  -1.5356655 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 22, State: [[ 0.01343633  1.1703439  -0.11016911 -1.8520491 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01343633  1.1703439  -0.11016911 -1.8520491 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 22, State: [[ 0.0368432   1.3664916  -0.14721009 -2.1768112 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0368432   1.3664916  -0.14721009 -2.1768112 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 22, State: [[ 0.06417304  1.5627074  -0.19074632 -2.5110753 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06417304  1.5627074  -0.19074632 -2.5110753 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 22, State: [[ 0.09542719  1.758817   -0.24096783 -2.8556442 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09542719  1.758817   -0.24096783 -2.8556442 ]], Done: True\n","Episode: 22, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 23, State: [[-0.0076961   0.18131478 -0.01178176 -0.25386998]], Action: 1, Reward: 1.0, Next State: [[-0.0076961   0.18131478 -0.01178176 -0.25386998]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 23, State: [[-0.0040698   0.37660298 -0.01685916 -0.5502457 ]], Action: 1, Reward: 1.0, Next State: [[-0.0040698   0.37660298 -0.01685916 -0.5502457 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 23, State: [[ 0.00346225  0.5719576  -0.02786407 -0.8481924 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00346225  0.5719576  -0.02786407 -0.8481924 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 23, State: [[ 0.01490141  0.7674483  -0.04482792 -1.1495056 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01490141  0.7674483  -0.04482792 -1.1495056 ]], Done: False\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 23, State: [[ 0.03025037  0.96312577 -0.06781803 -1.4559019 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03025037  0.96312577 -0.06781803 -1.4559019 ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 23, State: [[ 0.04951289  1.1590114  -0.09693607 -1.7689781 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04951289  1.1590114  -0.09693607 -1.7689781 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 23, State: [[ 0.07269312  1.355085   -0.13231564 -2.0901623 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07269312  1.355085   -0.13231564 -2.0901623 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 23, State: [[ 0.09979482  1.5512702  -0.17411888 -2.4206555 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09979482  1.5512702  -0.17411888 -2.4206555 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 23, State: [[ 0.13082023  1.7474182  -0.22253199 -2.7613611 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13082023  1.7474182  -0.22253199 -2.7613611 ]], Done: True\n","Episode: 23, Total Reward: 9.0\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 24, State: [[ 0.03206151  0.18097053 -0.02723522 -0.28054953]], Action: 1, Reward: 1.0, Next State: [[ 0.03206151  0.18097053 -0.02723522 -0.28054953]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 24, State: [[ 0.03568092  0.37647018 -0.03284621 -0.5816964 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03568092  0.37647018 -0.03284621 -0.5816964 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 24, State: [[ 0.04321033  0.57203656 -0.04448014 -0.8845428 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04321033  0.57203656 -0.04448014 -0.8845428 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 24, State: [[ 0.05465106  0.76773334 -0.062171   -1.1908705 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05465106  0.76773334 -0.062171   -1.1908705 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 24, State: [[ 0.07000573  0.9636033  -0.08598841 -1.5023744 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07000573  0.9636033  -0.08598841 -1.5023744 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 24, State: [[ 0.0892778   1.1596575  -0.11603589 -1.8206185 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0892778   1.1596575  -0.11603589 -1.8206185 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 24, State: [[ 0.11247094  1.3558618  -0.15244827 -2.1469839 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11247094  1.3558618  -0.15244827 -2.1469839 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 24, State: [[ 0.13958818  1.5521224  -0.19538794 -2.482607  ]], Action: 1, Reward: 1.0, Next State: [[ 0.13958818  1.5521224  -0.19538794 -2.482607  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 24, State: [[ 0.17063062  1.7482673  -0.24504007 -2.8283052 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17063062  1.7482673  -0.24504007 -2.8283052 ]], Done: True\n","Episode: 24, Total Reward: 9.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 25, State: [[ 0.01445858  0.21935451 -0.04824948 -0.35059837]], Action: 1, Reward: 1.0, Next State: [[ 0.01445858  0.21935451 -0.04824948 -0.35059837]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 25, State: [[ 0.01884567  0.41512826 -0.05526145 -0.658097  ]], Action: 1, Reward: 1.0, Next State: [[ 0.01884567  0.41512826 -0.05526145 -0.658097  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 25, State: [[ 0.02714824  0.6109741  -0.06842339 -0.96765596]], Action: 1, Reward: 1.0, Next State: [[ 0.02714824  0.6109741  -0.06842339 -0.96765596]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 25, State: [[ 0.03936772  0.8069448  -0.08777651 -1.2810249 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03936772  0.8069448  -0.08777651 -1.2810249 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 25, State: [[ 0.05550661  1.0030684  -0.11339701 -1.599851  ]], Action: 1, Reward: 1.0, Next State: [[ 0.05550661  1.0030684  -0.11339701 -1.599851  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 25, State: [[ 0.07556798  1.1993364  -0.14539403 -1.9256294 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07556798  1.1993364  -0.14539403 -1.9256294 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 25, State: [[ 0.09955471  1.3956885  -0.18390661 -2.2596455 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09955471  1.3956885  -0.18390661 -2.2596455 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 25, State: [[ 0.12746848  1.5919975  -0.22909953 -2.6029077 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12746848  1.5919975  -0.22909953 -2.6029077 ]], Done: True\n","Episode: 25, Total Reward: 8.0\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 26, State: [[-0.04858184  0.20881525  0.03130284 -0.2885487 ]], Action: 1, Reward: 1.0, Next State: [[-0.04858184  0.20881525  0.03130284 -0.2885487 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 26, State: [[-0.04440553  0.40347716  0.02553187 -0.571197  ]], Action: 1, Reward: 1.0, Next State: [[-0.04440553  0.40347716  0.02553187 -0.571197  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 26, State: [[-0.03633599  0.5982319   0.01410793 -0.8557284 ]], Action: 1, Reward: 1.0, Next State: [[-0.03633599  0.5982319   0.01410793 -0.8557284 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 26, State: [[-0.02437135  0.7931588  -0.00300664 -1.143942  ]], Action: 1, Reward: 1.0, Next State: [[-0.02437135  0.7931588  -0.00300664 -1.143942  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 26, State: [[-0.00850817  0.98831993 -0.02588548 -1.4375663 ]], Action: 1, Reward: 1.0, Next State: [[-0.00850817  0.98831993 -0.02588548 -1.4375663 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 26, State: [[ 0.01125822  1.1837512  -0.05463681 -1.7382245 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01125822  1.1837512  -0.05463681 -1.7382245 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 26, State: [[ 0.03493325  1.3794515  -0.0894013  -2.0473921 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03493325  1.3794515  -0.0894013  -2.0473921 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 26, State: [[ 0.06252228  1.5753694  -0.13034914 -2.3663442 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06252228  1.5753694  -0.13034914 -2.3663442 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 26, State: [[ 0.09402966  1.7713872  -0.17767602 -2.696091  ]], Action: 1, Reward: 1.0, Next State: [[ 0.09402966  1.7713872  -0.17767602 -2.696091  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 26, State: [[ 0.12945741  1.9673028  -0.23159784 -3.0373    ]], Action: 1, Reward: 1.0, Next State: [[ 0.12945741  1.9673028  -0.23159784 -3.0373    ]], Done: True\n","Episode: 26, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 27, State: [[ 0.02674857  0.23178819 -0.03822951 -0.33892336]], Action: 1, Reward: 1.0, Next State: [[ 0.02674857  0.23178819 -0.03822951 -0.33892336]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 27, State: [[ 0.03138433  0.4274327  -0.04500798 -0.6434124 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03138433  0.4274327  -0.04500798 -0.6434124 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 27, State: [[ 0.03993298  0.6231521  -0.05787623 -0.9499221 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03993298  0.6231521  -0.05787623 -0.9499221 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 27, State: [[ 0.05239603  0.81900334 -0.07687467 -1.2602133 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05239603  0.81900334 -0.07687467 -1.2602133 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 27, State: [[ 0.06877609  1.0150199  -0.10207893 -1.5759485 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06877609  1.0150199  -0.10207893 -1.5759485 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 27, State: [[ 0.08907649  1.2111996  -0.13359791 -1.8986455 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08907649  1.2111996  -0.13359791 -1.8986455 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 27, State: [[ 0.11330048  1.4074916  -0.17157081 -2.2296207 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11330048  1.4074916  -0.17157081 -2.2296207 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 27, State: [[ 0.14145032  1.6037794  -0.21616323 -2.5699244 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14145032  1.6037794  -0.21616323 -2.5699244 ]], Done: True\n","Episode: 27, Total Reward: 8.0\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 28, State: [[-0.02068223  0.16709928 -0.04109925 -0.33595386]], Action: 1, Reward: 1.0, Next State: [[-0.02068223  0.16709928 -0.04109925 -0.33595386]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 28, State: [[-0.01734024  0.3627813  -0.04781833 -0.6413088 ]], Action: 1, Reward: 1.0, Next State: [[-0.01734024  0.3627813  -0.04781833 -0.6413088 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 28, State: [[-0.01008462  0.5585361  -0.0606445  -0.9486585 ]], Action: 1, Reward: 1.0, Next State: [[-0.01008462  0.5585361  -0.0606445  -0.9486585 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 53ms/step\n","Episode: 28, State: [[ 1.0861066e-03  7.5441974e-01 -7.9617672e-02 -1.2597625e+00]], Action: 1, Reward: 1.0, Next State: [[ 1.0861066e-03  7.5441974e-01 -7.9617672e-02 -1.2597625e+00]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 28, State: [[ 0.0161745   0.95046484 -0.10481292 -1.5762814 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0161745   0.95046484 -0.10481292 -1.5762814 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 28, State: [[ 0.0351838   1.1466682  -0.13633855 -1.8997301 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0351838   1.1466682  -0.13633855 -1.8997301 ]], Done: False\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 28, State: [[ 0.05811716  1.3429774  -0.17433316 -2.2314208 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05811716  1.3429774  -0.17433316 -2.2314208 ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 28, State: [[ 0.08497671  1.5392746  -0.21896157 -2.572398  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08497671  1.5392746  -0.21896157 -2.572398  ]], Done: True\n","Episode: 28, Total Reward: 8.0\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 29, State: [[ 0.04264328  0.21900772 -0.03169676 -0.25896925]], Action: 1, Reward: 1.0, Next State: [[ 0.04264328  0.21900772 -0.03169676 -0.25896925]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 29, State: [[ 0.04702343  0.4145675  -0.03687614 -0.56147885]], Action: 1, Reward: 1.0, Next State: [[ 0.04702343  0.4145675  -0.03687614 -0.56147885]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 29, State: [[ 0.05531478  0.61018705 -0.04810572 -0.8655478 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05531478  0.61018705 -0.04810572 -0.8655478 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 29, State: [[ 0.06751852  0.80592954 -0.06541667 -1.1729596 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06751852  0.80592954 -0.06541667 -1.1729596 ]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 29, State: [[ 0.08363712  1.001838   -0.08887586 -1.4854125 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08363712  1.001838   -0.08887586 -1.4854125 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 29, State: [[ 0.10367388  1.1979238  -0.11858411 -1.8044753 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10367388  1.1979238  -0.11858411 -1.8044753 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 29, State: [[ 0.12763235  1.3941537  -0.15467362 -2.131535  ]], Action: 1, Reward: 1.0, Next State: [[ 0.12763235  1.3941537  -0.15467362 -2.131535  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 29, State: [[ 0.15551543  1.5904349  -0.19730432 -2.467735  ]], Action: 1, Reward: 1.0, Next State: [[ 0.15551543  1.5904349  -0.19730432 -2.467735  ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 29, State: [[ 0.18732412  1.7865975  -0.24665903 -2.813902  ]], Action: 1, Reward: 1.0, Next State: [[ 0.18732412  1.7865975  -0.24665903 -2.813902  ]], Done: True\n","Episode: 29, Total Reward: 9.0\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 30, State: [[ 0.04460545  0.15121952  0.01183199 -0.322133  ]], Action: 1, Reward: 1.0, Next State: [[ 0.04460545  0.15121952  0.01183199 -0.322133  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 30, State: [[ 0.04762984  0.346171    0.00538933 -0.6110612 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04762984  0.346171    0.00538933 -0.6110612 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 30, State: [[ 0.05455326  0.5412172  -0.0068319  -0.90204185]], Action: 1, Reward: 1.0, Next State: [[ 0.05455326  0.5412172  -0.0068319  -0.90204185]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 30, State: [[ 0.06537761  0.73643106 -0.02487273 -1.1968644 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06537761  0.73643106 -0.02487273 -1.1968644 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 30, State: [[ 0.08010623  0.93186593 -0.04881002 -1.4972379 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08010623  0.93186593 -0.04881002 -1.4972379 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 30, State: [[ 0.09874355  1.1275461  -0.07875478 -1.8047528 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09874355  1.1275461  -0.07875478 -1.8047528 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 30, State: [[ 0.12129447  1.323454   -0.11484984 -2.1208339 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12129447  1.323454   -0.11484984 -2.1208339 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 30, State: [[ 0.14776355  1.5195174  -0.15726651 -2.4466832 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14776355  1.5195174  -0.15726651 -2.4466832 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 30, State: [[ 0.1781539   1.7155912  -0.20620018 -2.7832103 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1781539   1.7155912  -0.20620018 -2.7832103 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 30, State: [[ 0.21246572  1.9114392  -0.2618644  -3.130953  ]], Action: 1, Reward: 1.0, Next State: [[ 0.21246572  1.9114392  -0.2618644  -3.130953  ]], Done: True\n","Episode: 30, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 31, State: [[ 0.02723432  0.22359867 -0.01238197 -0.27337456]], Action: 1, Reward: 1.0, Next State: [[ 0.02723432  0.22359867 -0.01238197 -0.27337456]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 31, State: [[ 0.0317063   0.4188951  -0.01784947 -0.56993693]], Action: 1, Reward: 1.0, Next State: [[ 0.0317063   0.4188951  -0.01784947 -0.56993693]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 31, State: [[ 0.04008419  0.61426276 -0.0292482  -0.8681892 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04008419  0.61426276 -0.0292482  -0.8681892 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 31, State: [[ 0.05236945  0.8097702  -0.04661199 -1.1699227 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05236945  0.8097702  -0.04661199 -1.1699227 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 31, State: [[ 0.06856485  1.0054663  -0.07001044 -1.476847  ]], Action: 1, Reward: 1.0, Next State: [[ 0.06856485  1.0054663  -0.07001044 -1.476847  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 31, State: [[ 0.08867418  1.2013701  -0.09954739 -1.790549  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08867418  1.2013701  -0.09954739 -1.790549  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 31, State: [[ 0.11270159  1.3974577  -0.13535836 -2.112443  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11270159  1.3974577  -0.13535836 -2.112443  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 31, State: [[ 0.14065073  1.5936483  -0.17760722 -2.443711  ]], Action: 1, Reward: 1.0, Next State: [[ 0.14065073  1.5936483  -0.17760722 -2.443711  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 31, State: [[ 0.1725237   1.7897869  -0.22648144 -2.7852333 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1725237   1.7897869  -0.22648144 -2.7852333 ]], Done: True\n","Episode: 31, Total Reward: 9.0\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 32, State: [[ 0.0482588   0.17559688 -0.04770633 -0.35440016]], Action: 1, Reward: 1.0, Next State: [[ 0.0482588   0.17559688 -0.04770633 -0.35440016]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 32, State: [[ 0.05177073  0.37136355 -0.05479433 -0.6617364 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05177073  0.37136355 -0.05479433 -0.6617364 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 32, State: [[ 0.059198    0.5672034  -0.06802906 -0.9711567 ]], Action: 1, Reward: 1.0, Next State: [[ 0.059198    0.5672034  -0.06802906 -0.9711567 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 32, State: [[ 0.07054207  0.76316917 -0.0874522  -1.2844106 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07054207  0.76316917 -0.0874522  -1.2844106 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 32, State: [[ 0.08580545  0.9592889  -0.11314041 -1.6031442 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08580545  0.9592889  -0.11314041 -1.6031442 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 32, State: [[ 0.10499123  1.1555535  -0.14520329 -1.9288511 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10499123  1.1555535  -0.14520329 -1.9288511 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 32, State: [[ 0.1281023   1.3519027  -0.18378031 -2.2628155 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1281023   1.3519027  -0.18378031 -2.2628155 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 32, State: [[ 0.15514036  1.5482088  -0.22903663 -2.6060438 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15514036  1.5482088  -0.22903663 -2.6060438 ]], Done: True\n","Episode: 32, Total Reward: 8.0\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 33, State: [[ 0.03550348  0.16125944  0.01970709 -0.27719998]], Action: 1, Reward: 1.0, Next State: [[ 0.03550348  0.16125944  0.01970709 -0.27719998]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 33, State: [[ 0.03872867  0.35609478  0.01416309 -0.56360275]], Action: 1, Reward: 1.0, Next State: [[ 0.03872867  0.35609478  0.01416309 -0.56360275]], Done: False\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 33, State: [[ 0.04585057  0.55101514  0.00289104 -0.8517902 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04585057  0.55101514  0.00289104 -0.8517902 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 33, State: [[ 0.05687087  0.74609756 -0.01414477 -1.1435627 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05687087  0.74609756 -0.01414477 -1.1435627 ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 33, State: [[ 0.07179283  0.9414015  -0.03701602 -1.4406476 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07179283  0.9414015  -0.03701602 -1.4406476 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 33, State: [[ 0.09062085  1.1369593  -0.06582897 -1.7446636 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09062085  1.1369593  -0.06582897 -1.7446636 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 33, State: [[ 0.11336004  1.3327652  -0.10072224 -2.057076  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11336004  1.3327652  -0.10072224 -2.057076  ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 33, State: [[ 0.14001535  1.5287619  -0.14186376 -2.3791432 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14001535  1.5287619  -0.14186376 -2.3791432 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 33, State: [[ 0.17059058  1.7248236  -0.18944663 -2.7118497 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17059058  1.7248236  -0.18944663 -2.7118497 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 33, State: [[ 0.20508705  1.9207385  -0.24368362 -3.0558288 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20508705  1.9207385  -0.24368362 -3.0558288 ]], Done: True\n","Episode: 33, Total Reward: 10.0\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 34, State: [[-0.0445595   0.21160656  0.02640205 -0.29583904]], Action: 1, Reward: 1.0, Next State: [[-0.0445595   0.21160656  0.02640205 -0.29583904]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 34, State: [[-0.04032737  0.40634236  0.02048527 -0.5800796 ]], Action: 1, Reward: 1.0, Next State: [[-0.04032737  0.40634236  0.02048527 -0.5800796 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 34, State: [[-0.03220052  0.6011714   0.00888368 -0.86623955]], Action: 1, Reward: 1.0, Next State: [[-0.03220052  0.6011714   0.00888368 -0.86623955]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 34, State: [[-0.02017709  0.7961713  -0.00844111 -1.1561161 ]], Action: 1, Reward: 1.0, Next State: [[-0.02017709  0.7961713  -0.00844111 -1.1561161 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 34, State: [[-0.00425366  0.99140227 -0.03156343 -1.4514338 ]], Action: 1, Reward: 1.0, Next State: [[-0.00425366  0.99140227 -0.03156343 -1.4514338 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 34, State: [[ 0.01557438  1.1868975  -0.06059211 -1.7538087 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01557438  1.1868975  -0.06059211 -1.7538087 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 34, State: [[ 0.03931233  1.382652   -0.09566829 -2.064705  ]], Action: 1, Reward: 1.0, Next State: [[ 0.03931233  1.382652   -0.09566829 -2.064705  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 34, State: [[ 0.06696537  1.5786096  -0.13696238 -2.3853807 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06696537  1.5786096  -0.13696238 -2.3853807 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 34, State: [[ 0.09853756  1.7746459  -0.18467    -2.7168226 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09853756  1.7746459  -0.18467    -2.7168226 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 34, State: [[ 0.13403048  1.9705509  -0.23900644 -3.0596685 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13403048  1.9705509  -0.23900644 -3.0596685 ]], Done: True\n","Episode: 34, Total Reward: 10.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 35, State: [[ 0.04077511  0.15176436 -0.04845299 -0.26430297]], Action: 1, Reward: 1.0, Next State: [[ 0.04077511  0.15176436 -0.04845299 -0.26430297]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 35, State: [[ 0.0438104   0.3475432  -0.05373905 -0.5718662 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0438104   0.3475432  -0.05373905 -0.5718662 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 35, State: [[ 0.05076126  0.5433759  -0.06517638 -0.8809829 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05076126  0.5433759  -0.06517638 -0.8809829 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 35, State: [[ 0.06162878  0.7393198  -0.08279604 -1.1934229 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06162878  0.7393198  -0.08279604 -1.1934229 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 35, State: [[ 0.07641517  0.9354107  -0.10666449 -1.5108659 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07641517  0.9354107  -0.10666449 -1.5108659 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 35, State: [[ 0.09512339  1.1316509  -0.13688181 -1.8348533 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09512339  1.1316509  -0.13688181 -1.8348533 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 35, State: [[ 0.1177564   1.3279959  -0.17357887 -2.1667335 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1177564   1.3279959  -0.17357887 -2.1667335 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 35, State: [[ 0.14431633  1.5243379  -0.21691355 -2.5075972 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14431633  1.5243379  -0.21691355 -2.5075972 ]], Done: True\n","Episode: 35, Total Reward: 8.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 36, State: [[-0.01862944  0.21674894  0.04625561 -0.23530416]], Action: 1, Reward: 1.0, Next State: [[-0.01862944  0.21674894  0.04625561 -0.23530416]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 36, State: [[-0.01429447  0.41118056  0.04154952 -0.5130453 ]], Action: 1, Reward: 1.0, Next State: [[-0.01429447  0.41118056  0.04154952 -0.5130453 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 36, State: [[-0.00607086  0.6056934   0.03128862 -0.79235077]], Action: 1, Reward: 1.0, Next State: [[-0.00607086  0.6056934   0.03128862 -0.79235077]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 36, State: [[ 0.00604301  0.8003721   0.0154416  -1.0750285 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00604301  0.8003721   0.0154416  -1.0750285 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 36, State: [[ 0.02205046  0.9952867  -0.00605897 -1.3628259 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02205046  0.9952867  -0.00605897 -1.3628259 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 36, State: [[ 0.04195619  1.190484   -0.03331549 -1.6573979 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04195619  1.190484   -0.03331549 -1.6573979 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 36, State: [[ 0.06576587  1.3859783  -0.06646345 -1.9602695 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06576587  1.3859783  -0.06646345 -1.9602695 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 36, State: [[ 0.09348544  1.5817385  -0.10566884 -2.2727873 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09348544  1.5817385  -0.10566884 -2.2727873 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 36, State: [[ 0.12512021  1.7776736  -0.15112458 -2.5960596 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12512021  1.7776736  -0.15112458 -2.5960596 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 36, State: [[ 0.16067368  1.9736152  -0.20304577 -2.9308836 ]], Action: 1, Reward: 1.0, Next State: [[ 0.16067368  1.9736152  -0.20304577 -2.9308836 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 36, State: [[ 0.20014597  2.1692975  -0.26166344 -3.2776635 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20014597  2.1692975  -0.26166344 -3.2776635 ]], Done: True\n","Episode: 36, Total Reward: 11.0\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 37, State: [[ 0.01746353  0.2371552  -0.03705449 -0.3303541 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01746353  0.2371552  -0.03705449 -0.3303541 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 37, State: [[ 0.02220663  0.4327845  -0.04366158 -0.6344881 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02220663  0.4327845  -0.04366158 -0.6344881 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 37, State: [[ 0.03086232  0.6284874  -0.05635134 -0.94059515]], Action: 1, Reward: 1.0, Next State: [[ 0.03086232  0.6284874  -0.05635134 -0.94059515]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 50ms/step\n","Episode: 37, State: [[ 0.04343207  0.82432175 -0.07516325 -1.2504389 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04343207  0.82432175 -0.07516325 -1.2504389 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 37, State: [[ 0.0599185   1.0203222  -0.10017202 -1.5656866 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0599185   1.0203222  -0.10017202 -1.5656866 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 37, State: [[ 0.08032495  1.2164884  -0.13148575 -1.8878623 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08032495  1.2164884  -0.13148575 -1.8878623 ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 55ms/step\n","Episode: 37, State: [[ 0.10465471  1.4127717  -0.169243   -2.2182913 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10465471  1.4127717  -0.169243   -2.2182913 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 37, State: [[ 0.13291015  1.6090586  -0.21360882 -2.5580354 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13291015  1.6090586  -0.21360882 -2.5580354 ]], Done: True\n","Episode: 37, Total Reward: 8.0\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 38, State: [[ 0.04137902  0.243563    0.01284347 -0.2935589 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04137902  0.243563    0.01284347 -0.2935589 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 38, State: [[ 0.04625028  0.4384995   0.0069723  -0.58216363]], Action: 1, Reward: 1.0, Next State: [[ 0.04625028  0.4384995   0.0069723  -0.58216363]], Done: False\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 38, State: [[ 0.05502027  0.63352305 -0.00467098 -0.87264204]], Action: 1, Reward: 1.0, Next State: [[ 0.05502027  0.63352305 -0.00467098 -0.87264204]], Done: False\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 38, State: [[ 0.06769074  0.82870823 -0.02212382 -1.1667899 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06769074  0.82870823 -0.02212382 -1.1667899 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 38, State: [[ 0.0842649   1.024111   -0.04545962 -1.4663261 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0842649   1.024111   -0.04545962 -1.4663261 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 38, State: [[ 0.10474712  1.2197591  -0.07478614 -1.7728556 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10474712  1.2197591  -0.07478614 -1.7728556 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 38, State: [[ 0.1291423   1.4156405  -0.11024325 -2.0878232 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1291423   1.4156405  -0.11024325 -2.0878232 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 38, State: [[ 0.15745512  1.6116892  -0.15199971 -2.4124568 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15745512  1.6116892  -0.15199971 -2.4124568 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 38, State: [[ 0.18968889  1.807769   -0.20024885 -2.7477014 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18968889  1.807769   -0.20024885 -2.7477014 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 38, State: [[ 0.22584428  2.0036542  -0.2552029  -3.0941384 ]], Action: 1, Reward: 1.0, Next State: [[ 0.22584428  2.0036542  -0.2552029  -3.0941384 ]], Done: True\n","Episode: 38, Total Reward: 10.0\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 39, State: [[-0.03932827  0.23420861  0.02526698 -0.24963777]], Action: 1, Reward: 1.0, Next State: [[-0.03932827  0.23420861  0.02526698 -0.24963777]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 39, State: [[-0.0346441   0.4289608   0.02027423 -0.5342451 ]], Action: 1, Reward: 1.0, Next State: [[-0.0346441   0.4289608   0.02027423 -0.5342451 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 39, State: [[-0.02606488  0.6237919   0.00958933 -0.8204714 ]], Action: 1, Reward: 1.0, Next State: [[-0.02606488  0.6237919   0.00958933 -0.8204714 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 39, State: [[-0.01358905  0.81878126 -0.0068201  -1.1101228 ]], Action: 1, Reward: 1.0, Next State: [[-0.01358905  0.81878126 -0.0068201  -1.1101228 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 39, State: [[ 0.00278658  1.0139922  -0.02902256 -1.4049375 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00278658  1.0139922  -0.02902256 -1.4049375 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 39, State: [[ 0.02306642  1.2094622  -0.05712131 -1.7065505 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02306642  1.2094622  -0.05712131 -1.7065505 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 39, State: [[ 0.04725567  1.4051926  -0.09125232 -2.0164518 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04725567  1.4051926  -0.09125232 -2.0164518 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 39, State: [[ 0.07535952  1.6011355  -0.13158135 -2.3359342 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07535952  1.6011355  -0.13158135 -2.3359342 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 39, State: [[ 0.10738223  1.7971774  -0.17830004 -2.6660285 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10738223  1.7971774  -0.17830004 -2.6660285 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 39, State: [[ 0.14332578  1.9931217  -0.23162061 -3.0074284 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14332578  1.9931217  -0.23162061 -3.0074284 ]], Done: True\n","Episode: 39, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 40, State: [[-0.01798039  0.14622112 -0.04879604 -0.26001516]], Action: 1, Reward: 1.0, Next State: [[-0.01798039  0.14622112 -0.04879604 -0.26001516]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 40, State: [[-0.01505597  0.34200445 -0.05399634 -0.56768095]], Action: 1, Reward: 1.0, Next State: [[-0.01505597  0.34200445 -0.05399634 -0.56768095]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 40, State: [[-0.00821588  0.5378406  -0.06534996 -0.8768742 ]], Action: 1, Reward: 1.0, Next State: [[-0.00821588  0.5378406  -0.06534996 -0.8768742 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 40, State: [[ 0.00254093  0.73378694 -0.08288745 -1.1893656 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00254093  0.73378694 -0.08288745 -1.1893656 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 40, State: [[ 0.01721667  0.9298796  -0.10667476 -1.5068357 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01721667  0.9298796  -0.10667476 -1.5068357 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 40, State: [[ 0.03581426  1.1261212  -0.13681148 -1.8308278 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03581426  1.1261212  -0.13681148 -1.8308278 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 40, State: [[ 0.05833668  1.3224676  -0.17342803 -2.1626925 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05833668  1.3224676  -0.17342803 -2.1626925 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 40, State: [[ 0.08478604  1.518812   -0.21668188 -2.5035238 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08478604  1.518812   -0.21668188 -2.5035238 ]], Done: True\n","Episode: 40, Total Reward: 8.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 41, State: [[ 0.02119125  0.22649215  0.02515859 -0.27808222]], Action: 1, Reward: 1.0, Next State: [[ 0.02119125  0.22649215  0.02515859 -0.27808222]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 41, State: [[ 0.02572109  0.42124632  0.01959695 -0.5627252 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02572109  0.42124632  0.01959695 -0.5627252 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 41, State: [[ 0.03414602  0.61608785  0.00834244 -0.84917027]], Action: 1, Reward: 1.0, Next State: [[ 0.03414602  0.61608785  0.00834244 -0.84917027]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 41, State: [[ 0.04646777  0.81109506 -0.00864096 -1.1392182 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04646777  0.81109506 -0.00864096 -1.1392182 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 41, State: [[ 0.06268968  1.0063289  -0.03142532 -1.4345984 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06268968  1.0063289  -0.03142532 -1.4345984 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 41, State: [[ 0.08281626  1.2018241  -0.06011729 -1.736934  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08281626  1.2018241  -0.06011729 -1.736934  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 41, State: [[ 0.10685274  1.3975775  -0.09485597 -2.0476975 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10685274  1.3975775  -0.09485597 -2.0476975 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 41, State: [[ 0.1348043   1.5935357  -0.13580993 -2.3681593 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1348043   1.5935357  -0.13580993 -2.3681593 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 41, State: [[ 0.166675   1.7895777 -0.1831731 -2.69932  ]], Action: 1, Reward: 1.0, Next State: [[ 0.166675   1.7895777 -0.1831731 -2.69932  ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Episode: 41, State: [[ 0.20246656  1.9854978  -0.2371595  -3.041836  ]], Action: 1, Reward: 1.0, Next State: [[ 0.20246656  1.9854978  -0.2371595  -3.041836  ]], Done: True\n","Episode: 41, Total Reward: 10.0\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 42, State: [[ 0.02513929  0.23637515  0.03543045 -0.24430671]], Action: 1, Reward: 1.0, Next State: [[ 0.02513929  0.23637515  0.03543045 -0.24430671]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 42, State: [[ 0.02986679  0.4309736   0.03054431 -0.5256068 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02986679  0.4309736   0.03054431 -0.5256068 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 42, State: [[ 0.03848626  0.62565273  0.02003217 -0.80851066]], Action: 1, Reward: 1.0, Next State: [[ 0.03848626  0.62565273  0.02003217 -0.80851066]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 42, State: [[ 0.05099931  0.82049453  0.00386196 -1.0948256 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05099931  0.82049453  0.00386196 -1.0948256 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 53ms/step\n","Episode: 42, State: [[ 0.0674092   1.0155654  -0.01803455 -1.3862944 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0674092   1.0155654  -0.01803455 -1.3862944 ]], Done: False\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 54ms/step\n","Episode: 42, State: [[ 0.08772051  1.2109075  -0.04576044 -1.6845617 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08772051  1.2109075  -0.04576044 -1.6845617 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 42, State: [[ 0.11193866  1.4065281  -0.07945167 -1.9911344 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11193866  1.4065281  -0.07945167 -1.9911344 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 42, State: [[ 0.14006922  1.6023875  -0.11927436 -2.3073308 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14006922  1.6023875  -0.11927436 -2.3073308 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 42, State: [[ 0.17211698  1.7983828  -0.16542098 -2.6342187 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17211698  1.7983828  -0.16542098 -2.6342187 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 42, State: [[ 0.20808463  1.9943305  -0.21810535 -2.9725401 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20808463  1.9943305  -0.21810535 -2.9725401 ]], Done: True\n","Episode: 42, Total Reward: 10.0\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 43, State: [[ 0.03666381  0.18343368 -0.02627323 -0.25292417]], Action: 1, Reward: 1.0, Next State: [[ 0.03666381  0.18343368 -0.02627323 -0.25292417]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 43, State: [[ 0.04033248  0.37892073 -0.03133171 -0.55377704]], Action: 1, Reward: 1.0, Next State: [[ 0.04033248  0.37892073 -0.03133171 -0.55377704]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 43, State: [[ 0.0479109   0.5744683  -0.04240726 -0.85616446]], Action: 1, Reward: 1.0, Next State: [[ 0.0479109   0.5744683  -0.04240726 -0.85616446]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 43, State: [[ 0.05940026  0.77014166 -0.05953055 -1.1618747 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05940026  0.77014166 -0.05953055 -1.1618747 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 43, State: [[ 0.0748031   0.9659863  -0.08276804 -1.4726127 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0748031   0.9659863  -0.08276804 -1.4726127 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 43, State: [[ 0.09412282  1.1620169  -0.11222029 -1.7899581 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09412282  1.1620169  -0.11222029 -1.7899581 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 43, State: [[ 0.11736316  1.3582047  -0.14801945 -2.1153123 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11736316  1.3582047  -0.14801945 -2.1153123 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 43, State: [[ 0.14452726  1.5544624  -0.19032569 -2.4498389 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14452726  1.5544624  -0.19032569 -2.4498389 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 43, State: [[ 0.1756165   1.7506272  -0.23932247 -2.7943912 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1756165   1.7506272  -0.23932247 -2.7943912 ]], Done: True\n","Episode: 43, Total Reward: 9.0\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 44, State: [[-0.0226379   0.18613134  0.01123855 -0.31193   ]], Action: 1, Reward: 1.0, Next State: [[-0.0226379   0.18613134  0.01123855 -0.31193   ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 44, State: [[-0.01891527  0.3810914   0.00499995 -0.6010476 ]], Action: 1, Reward: 1.0, Next State: [[-0.01891527  0.3810914   0.00499995 -0.6010476 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 44, State: [[-0.01129344  0.576143   -0.007021   -0.8921514 ]], Action: 1, Reward: 1.0, Next State: [[-0.01129344  0.576143   -0.007021   -0.8921514 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 44, State: [[ 2.2941915e-04  7.7135950e-01 -2.4864027e-02 -1.1870331e+00]], Action: 1, Reward: 1.0, Next State: [[ 2.2941915e-04  7.7135950e-01 -2.4864027e-02 -1.1870331e+00]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 44, State: [[ 0.01565661  0.9667949  -0.04860469 -1.4874048 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01565661  0.9667949  -0.04860469 -1.4874048 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 44, State: [[ 0.03499251  1.1624742  -0.07835279 -1.7948612 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03499251  1.1624742  -0.07835279 -1.7948612 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 44, State: [[ 0.05824199  1.3583814  -0.11425    -2.1108327 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05824199  1.3583814  -0.11425    -2.1108327 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 44, State: [[ 0.08540962  1.5544456  -0.15646666 -2.436528  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08540962  1.5544456  -0.15646666 -2.436528  ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 44, State: [[ 0.11649853  1.7505242  -0.20519722 -2.7728667 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11649853  1.7505242  -0.20519722 -2.7728667 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 44, State: [[ 0.15150902  1.9463836  -0.26065457 -3.1203978 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15150902  1.9463836  -0.26065457 -3.1203978 ]], Done: True\n","Episode: 44, Total Reward: 10.0\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 45, State: [[ 0.03331414  0.242047   -0.02874124 -0.3118264 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03331414  0.242047   -0.02874124 -0.3118264 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 45, State: [[ 0.03815508  0.43756637 -0.03497777 -0.6134331 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03815508  0.43756637 -0.03497777 -0.6134331 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 45, State: [[ 0.04690641  0.6331592  -0.04724643 -0.91692424]], Action: 1, Reward: 1.0, Next State: [[ 0.04690641  0.6331592  -0.04724643 -0.91692424]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 45, State: [[ 0.05956959  0.82888705 -0.06558492 -1.2240736 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05956959  0.82888705 -0.06558492 -1.2240736 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 45, State: [[ 0.07614733  1.0247895  -0.09006639 -1.5365638 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07614733  1.0247895  -0.09006639 -1.5365638 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 45, State: [[ 0.09664312  1.2208729  -0.12079766 -1.8559405 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09664312  1.2208729  -0.12079766 -1.8559405 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 45, State: [[ 0.12106058  1.417097   -0.15791647 -2.18356   ]], Action: 1, Reward: 1.0, Next State: [[ 0.12106058  1.417097   -0.15791647 -2.18356   ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 45, State: [[ 0.14940251  1.6133596  -0.20158768 -2.5205255 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14940251  1.6133596  -0.20158768 -2.5205255 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 45, State: [[ 0.18166971  1.8094786  -0.2519982  -2.867613  ]], Action: 1, Reward: 1.0, Next State: [[ 0.18166971  1.8094786  -0.2519982  -2.867613  ]], Done: True\n","Episode: 45, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 46, State: [[-0.00028565  0.19408064  0.03495825 -0.239497  ]], Action: 1, Reward: 1.0, Next State: [[-0.00028565  0.19408064  0.03495825 -0.239497  ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 46, State: [[ 0.00359597  0.3886862   0.03016831 -0.5209514 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00359597  0.3886862   0.03016831 -0.5209514 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 46, State: [[ 0.01136969  0.5833708   0.01974928 -0.80397725]], Action: 1, Reward: 1.0, Next State: [[ 0.01136969  0.5833708   0.01974928 -0.80397725]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 46, State: [[ 0.02303711  0.7782165   0.00366974 -1.0903828 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02303711  0.7782165   0.00366974 -1.0903828 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 46, State: [[ 0.03860144  0.97328985 -0.01813792 -1.3819121 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03860144  0.97328985 -0.01813792 -1.3819121 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 72ms/step\n","Episode: 46, State: [[ 0.05806723  1.1686333  -0.04577616 -1.6802114 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05806723  1.1686333  -0.04577616 -1.6802114 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 46, State: [[ 0.0814399   1.364255   -0.07938039 -1.9867898 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0814399   1.364255   -0.07938039 -1.9867898 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 46, State: [[ 0.108725    1.560115   -0.11911619 -2.3029683 ]], Action: 1, Reward: 1.0, Next State: [[ 0.108725    1.560115   -0.11911619 -2.3029683 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 46, State: [[ 0.1399273   1.7561117  -0.16517554 -2.6298175 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1399273   1.7561117  -0.16517554 -2.6298175 ]], Done: False\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 46, State: [[ 0.17504953  1.9520626  -0.2177719  -2.9680843 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17504953  1.9520626  -0.2177719  -2.9680843 ]], Done: True\n","Episode: 46, Total Reward: 10.0\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 47, State: [[ 0.03845858  0.22995701 -0.02977478 -0.3373608 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03845858  0.22995701 -0.02977478 -0.3373608 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 47, State: [[ 0.04305772  0.42548975 -0.03652199 -0.63928235]], Action: 1, Reward: 1.0, Next State: [[ 0.04305772  0.42548975 -0.03652199 -0.63928235]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 50ms/step\n","Episode: 47, State: [[ 0.05156751  0.6211014  -0.04930764 -0.9432392 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05156751  0.6211014  -0.04930764 -0.9432392 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 47, State: [[ 0.06398954  0.81685174 -0.06817243 -1.2509985 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06398954  0.81685174 -0.06817243 -1.2509985 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 47, State: [[ 0.08032658  1.0127778  -0.09319239 -1.5642321 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08032658  1.0127778  -0.09319239 -1.5642321 ]], Done: False\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 47, State: [[ 0.10058213  1.2088822  -0.12447704 -1.8844712 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10058213  1.2088822  -0.12447704 -1.8844712 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 47, State: [[ 0.12475978  1.4051194  -0.16216646 -2.2130513 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12475978  1.4051194  -0.16216646 -2.2130513 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 47, State: [[ 0.15286216  1.6013807  -0.20642748 -2.551049  ]], Action: 1, Reward: 1.0, Next State: [[ 0.15286216  1.6013807  -0.20642748 -2.551049  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 47, State: [[ 0.18488978  1.7974756  -0.25744846 -2.8992062 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18488978  1.7974756  -0.25744846 -2.8992062 ]], Done: True\n","Episode: 47, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 48, State: [[ 0.03590795  0.21149307 -0.01233394 -0.26052463]], Action: 1, Reward: 1.0, Next State: [[ 0.03590795  0.21149307 -0.01233394 -0.26052463]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 48, State: [[ 0.04013782  0.40678892 -0.01754443 -0.55707216]], Action: 1, Reward: 1.0, Next State: [[ 0.04013782  0.40678892 -0.01754443 -0.55707216]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 48, State: [[ 0.04827359  0.6021527  -0.02868587 -0.85523057]], Action: 1, Reward: 1.0, Next State: [[ 0.04827359  0.6021527  -0.02868587 -0.85523057]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 48, State: [[ 0.06031665  0.7976536  -0.04579048 -1.1567937 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06031665  0.7976536  -0.04579048 -1.1567937 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 48, State: [[ 0.07626972  0.99334157 -0.06892636 -1.4634757 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07626972  0.99334157 -0.06892636 -1.4634757 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 48, State: [[ 0.09613655  1.189237   -0.09819587 -1.7768694 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09613655  1.189237   -0.09819587 -1.7768694 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 48, State: [[ 0.11992129  1.3853183  -0.13373326 -2.0983977 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11992129  1.3853183  -0.13373326 -2.0983977 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 48, State: [[ 0.14762765  1.5815074  -0.17570122 -2.4292543 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14762765  1.5815074  -0.17570122 -2.4292543 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 48, State: [[ 0.17925781  1.7776527  -0.2242863  -2.7703333 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17925781  1.7776527  -0.2242863  -2.7703333 ]], Done: True\n","Episode: 48, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 49, State: [[ 0.04360632  0.19167978  0.00967011 -0.33145702]], Action: 1, Reward: 1.0, Next State: [[ 0.04360632  0.19167978  0.00967011 -0.33145702]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 49, State: [[ 0.04743992  0.38666275  0.00304097 -0.62107486]], Action: 1, Reward: 1.0, Next State: [[ 0.04743992  0.38666275  0.00304097 -0.62107486]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 49, State: [[ 0.05517317  0.5817421  -0.00938053 -0.91279846]], Action: 1, Reward: 1.0, Next State: [[ 0.05517317  0.5817421  -0.00938053 -0.91279846]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 49, State: [[ 0.06680802  0.7769897  -0.0276365  -1.2084148 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06680802  0.7769897  -0.0276365  -1.2084148 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 49, State: [[ 0.08234781  0.9724575  -0.05180479 -1.5096287 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08234781  0.9724575  -0.05180479 -1.5096287 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 49, State: [[ 0.10179696  1.1681676  -0.08199736 -1.8180237 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10179696  1.1681676  -0.08199736 -1.8180237 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 49, State: [[ 0.1251603   1.3641     -0.11835784 -2.135015  ]], Action: 1, Reward: 1.0, Next State: [[ 0.1251603   1.3641     -0.11835784 -2.135015  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 49, State: [[ 0.1524423   1.5601783  -0.16105814 -2.4617908 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1524423   1.5601783  -0.16105814 -2.4617908 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 49, State: [[ 0.18364587  1.7562532  -0.21029396 -2.7992435 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18364587  1.7562532  -0.21029396 -2.7992435 ]], Done: True\n","Episode: 49, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 50, State: [[ 0.00804097  0.21966869  0.01957833 -0.25127763]], Action: 1, Reward: 1.0, Next State: [[ 0.00804097  0.21966869  0.01957833 -0.25127763]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 50, State: [[ 0.01243434  0.41450566  0.01455278 -0.5377214 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01243434  0.41450566  0.01455278 -0.5377214 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 50, State: [[ 0.02072446  0.60942     0.00379835 -0.8257836 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02072446  0.60942     0.00379835 -0.8257836 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 50, State: [[ 0.03291286  0.80448985 -0.01271733 -1.1172695 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03291286  0.80448985 -0.01271733 -1.1172695 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 50, State: [[ 0.04900265  0.99977636 -0.03506272 -1.4139144 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04900265  0.99977636 -0.03506272 -1.4139144 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 50, State: [[ 0.06899818  1.1953148  -0.06334101 -1.7173481 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06899818  1.1953148  -0.06334101 -1.7173481 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 50, State: [[ 0.09290448  1.3911031  -0.09768797 -2.0290515 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09290448  1.3911031  -0.09768797 -2.0290515 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 50, State: [[ 0.12072654  1.5870891  -0.13826899 -2.3503034 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12072654  1.5870891  -0.13826899 -2.3503034 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 50, State: [[ 0.15246832  1.7831535  -0.18527506 -2.6821148 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15246832  1.7831535  -0.18527506 -2.6821148 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 50, State: [[ 0.18813139  1.9790927  -0.23891737 -3.0251534 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18813139  1.9790927  -0.23891737 -3.0251534 ]], Done: True\n","Episode: 50, Total Reward: 10.0\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 51, State: [[-3.9659034e-02  1.6449636e-01 -1.8080464e-04 -3.2972685e-01]], Action: 1, Reward: 1.0, Next State: [[-3.9659034e-02  1.6449636e-01 -1.8080464e-04 -3.2972685e-01]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 51, State: [[-0.03636911  0.3596209  -0.00677534 -0.6224668 ]], Action: 1, Reward: 1.0, Next State: [[-0.03636911  0.3596209  -0.00677534 -0.6224668 ]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 47ms/step\n","Episode: 51, State: [[-0.02917669  0.5548368  -0.01922468 -0.91727585]], Action: 1, Reward: 1.0, Next State: [[-0.02917669  0.5548368  -0.01922468 -0.91727585]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 51, State: [[-0.01807995  0.7502133  -0.03757019 -1.2159382 ]], Action: 1, Reward: 1.0, Next State: [[-0.01807995  0.7502133  -0.03757019 -1.2159382 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 51, State: [[-0.00307569  0.94579923 -0.06188896 -1.520153  ]], Action: 1, Reward: 1.0, Next State: [[-0.00307569  0.94579923 -0.06188896 -1.520153  ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 51, State: [[ 0.0158403   1.1416122  -0.09229202 -1.831494  ]], Action: 1, Reward: 1.0, Next State: [[ 0.0158403   1.1416122  -0.09229202 -1.831494  ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 51, State: [[ 0.03867254  1.3376268  -0.1289219  -2.15136   ]], Action: 1, Reward: 1.0, Next State: [[ 0.03867254  1.3376268  -0.1289219  -2.15136   ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 51, State: [[ 0.06542508  1.5337596  -0.1719491  -2.4809155 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06542508  1.5337596  -0.1719491  -2.4809155 ]], Done: False\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 51, State: [[ 0.09610027  1.7298517  -0.2215674  -2.8210204 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09610027  1.7298517  -0.2215674  -2.8210204 ]], Done: True\n","Episode: 51, Total Reward: 9.0\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 52, State: [[ 0.04315837  0.16485374  0.02626961 -0.3005879 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04315837  0.16485374  0.02626961 -0.3005879 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 52, State: [[ 0.04645544  0.3595916   0.02025785 -0.58487153]], Action: 1, Reward: 1.0, Next State: [[ 0.04645544  0.3595916   0.02025785 -0.58487153]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 52, State: [[ 0.05364727  0.55442405  0.00856042 -0.8711048 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05364727  0.55442405  0.00856042 -0.8711048 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 52, State: [[ 0.06473576  0.7494285  -0.00886168 -1.161084  ]], Action: 1, Reward: 1.0, Next State: [[ 0.06473576  0.7494285  -0.00886168 -1.161084  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 52, State: [[ 0.07972433  0.9446648  -0.03208336 -1.4565322 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07972433  0.9446648  -0.03208336 -1.4565322 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 52, State: [[ 0.09861762  1.1401654  -0.061214   -1.7590631 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09861762  1.1401654  -0.061214   -1.7590631 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 52, State: [[ 0.12142093  1.3359247  -0.09639527 -2.070138  ]], Action: 1, Reward: 1.0, Next State: [[ 0.12142093  1.3359247  -0.09639527 -2.070138  ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 52, State: [[ 0.14813942  1.5318854  -0.13779803 -2.3910105 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14813942  1.5318854  -0.13779803 -2.3910105 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 52, State: [[ 0.17877713  1.7279218  -0.18561824 -2.7226624 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17877713  1.7279218  -0.18561824 -2.7226624 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 52, State: [[ 0.21333557  1.9238222  -0.24007149 -3.0657241 ]], Action: 1, Reward: 1.0, Next State: [[ 0.21333557  1.9238222  -0.24007149 -3.0657241 ]], Done: True\n","Episode: 52, Total Reward: 10.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Episode: 53, State: [[-0.01167432  0.24335192  0.01170602 -0.2674737 ]], Action: 1, Reward: 1.0, Next State: [[-0.01167432  0.24335192  0.01170602 -0.2674737 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 53, State: [[-0.00680729  0.43830487  0.00635654 -0.5564416 ]], Action: 1, Reward: 1.0, Next State: [[-0.00680729  0.43830487  0.00635654 -0.5564416 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 53, State: [[ 0.00195881  0.633337   -0.00477229 -0.84711504]], Action: 1, Reward: 1.0, Next State: [[ 0.00195881  0.633337   -0.00477229 -0.84711504]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 53, State: [[ 0.01462555  0.82852376 -0.02171459 -1.1412948 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01462555  0.82852376 -0.02171459 -1.1412948 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 53, State: [[ 0.03119603  1.0239227  -0.04454049 -1.4407078 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03119603  1.0239227  -0.04454049 -1.4407078 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 53, State: [[ 0.05167448  1.219564   -0.07335465 -1.7469693 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05167448  1.219564   -0.07335465 -1.7469693 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 53, State: [[ 0.07606576  1.415439   -0.10829403 -2.0615387 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07606576  1.415439   -0.10829403 -2.0615387 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 53, State: [[ 0.10437454  1.6114862  -0.14952481 -2.385663  ]], Action: 1, Reward: 1.0, Next State: [[ 0.10437454  1.6114862  -0.14952481 -2.385663  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 53, State: [[ 0.13660426  1.8075752  -0.19723806 -2.7203112 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13660426  1.8075752  -0.19723806 -2.7203112 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 53, State: [[ 0.17275576  2.0034878  -0.25164428 -3.066095  ]], Action: 1, Reward: 1.0, Next State: [[ 0.17275576  2.0034878  -0.25164428 -3.066095  ]], Done: True\n","Episode: 53, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 54, State: [[ 0.03526232  0.2227292  -0.03908557 -0.2680608 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03526232  0.2227292  -0.03908557 -0.2680608 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 54, State: [[ 0.0397169   0.41838655 -0.04444679 -0.5728109 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0397169   0.41838655 -0.04444679 -0.5728109 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 54, State: [[ 0.04808463  0.6141026  -0.05590301 -0.8791581 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04808463  0.6141026  -0.05590301 -0.8791581 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 54, State: [[ 0.06036668  0.8099377  -0.07348616 -1.1888788 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06036668  0.8099377  -0.07348616 -1.1888788 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 54, State: [[ 0.07656544  1.0059313  -0.09726375 -1.5036612 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07656544  1.0059313  -0.09726375 -1.5036612 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 54, State: [[ 0.09668406  1.2020898  -0.12733696 -1.8250587 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09668406  1.2020898  -0.12733696 -1.8250587 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 54, State: [[ 0.12072586  1.398374   -0.16383813 -2.154437  ]], Action: 1, Reward: 1.0, Next State: [[ 0.12072586  1.398374   -0.16383813 -2.154437  ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 54, State: [[ 0.14869334  1.5946829  -0.20692688 -2.4929106 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14869334  1.5946829  -0.20692688 -2.4929106 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 54, State: [[ 0.180587   1.790837  -0.2567851 -2.841268 ]], Action: 1, Reward: 1.0, Next State: [[ 0.180587   1.790837  -0.2567851 -2.841268 ]], Done: True\n","Episode: 54, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 55, State: [[ 0.043328    0.17601869  0.04212312 -0.28688693]], Action: 1, Reward: 1.0, Next State: [[ 0.043328    0.17601869  0.04212312 -0.28688693]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 55, State: [[ 0.04684837  0.37051538  0.03638539 -0.56599265]], Action: 1, Reward: 1.0, Next State: [[ 0.04684837  0.37051538  0.03638539 -0.56599265]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 55, State: [[ 0.05425868  0.56510854  0.02506553 -0.8469942 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05425868  0.56510854  0.02506553 -0.8469942 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 55, State: [[ 0.06556085  0.7598797   0.00812565 -1.1316907 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06556085  0.7598797   0.00812565 -1.1316907 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 55, State: [[ 0.08075844  0.95489436 -0.01450817 -1.4218141 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08075844  0.95489436 -0.01450817 -1.4218141 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 43ms/step\n","Episode: 55, State: [[ 0.09985633  1.1501927  -0.04294445 -1.718996  ]], Action: 1, Reward: 1.0, Next State: [[ 0.09985633  1.1501927  -0.04294445 -1.718996  ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 55, State: [[ 0.12286019  1.3457797  -0.07732437 -2.0247278 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12286019  1.3457797  -0.07732437 -2.0247278 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 55, State: [[ 0.14977577  1.5416117  -0.11781893 -2.340309  ]], Action: 1, Reward: 1.0, Next State: [[ 0.14977577  1.5416117  -0.11781893 -2.340309  ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 55, State: [[ 0.18060802  1.7375815  -0.16462511 -2.6667843 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18060802  1.7375815  -0.16462511 -2.6667843 ]], Done: False\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 55, State: [[ 0.21535964  1.9334999  -0.21796079 -3.0048702 ]], Action: 1, Reward: 1.0, Next State: [[ 0.21535964  1.9334999  -0.21796079 -3.0048702 ]], Done: True\n","Episode: 55, Total Reward: 10.0\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 56, State: [[-0.02270373  0.22038382 -0.01668094 -0.3049968 ]], Action: 1, Reward: 1.0, Next State: [[-0.02270373  0.22038382 -0.01668094 -0.3049968 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 56, State: [[-0.01829606  0.41573948 -0.02278088 -0.6028935 ]], Action: 1, Reward: 1.0, Next State: [[-0.01829606  0.41573948 -0.02278088 -0.6028935 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 56, State: [[-0.00998127  0.6111725  -0.03483875 -0.90266395]], Action: 1, Reward: 1.0, Next State: [[-0.00998127  0.6111725  -0.03483875 -0.90266395]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 46ms/step\n","Episode: 56, State: [[ 0.00224218  0.8067486  -0.05289203 -1.2060907 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00224218  0.8067486  -0.05289203 -1.2060907 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 56, State: [[ 0.01837716  1.0025127  -0.07701384 -1.5148691 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01837716  1.0025127  -0.07701384 -1.5148691 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 56, State: [[ 0.03842741  1.1984776  -0.10731122 -1.8305649 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03842741  1.1984776  -0.10731122 -1.8305649 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 54ms/step\n","Episode: 56, State: [[ 0.06239696  1.394612   -0.14392252 -2.1545632 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06239696  1.394612   -0.14392252 -2.1545632 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 56, State: [[ 0.09028921  1.5908247  -0.18701378 -2.4880066 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09028921  1.5908247  -0.18701378 -2.4880066 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 56, State: [[ 0.1221057   1.7869477  -0.23677391 -2.8317237 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1221057   1.7869477  -0.23677391 -2.8317237 ]], Done: True\n","Episode: 56, Total Reward: 9.0\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 57, State: [[-0.04180096  0.22773811  0.04161406 -0.27429333]], Action: 1, Reward: 1.0, Next State: [[-0.04180096  0.22773811  0.04161406 -0.27429333]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 57, State: [[-0.0372462   0.42224237  0.03612819 -0.55356616]], Action: 1, Reward: 1.0, Next State: [[-0.0372462   0.42224237  0.03612819 -0.55356616]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 57, State: [[-0.02880136  0.6168389   0.02505687 -0.834651  ]], Action: 1, Reward: 1.0, Next State: [[-0.02880136  0.6168389   0.02505687 -0.834651  ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 57, State: [[-0.01646458  0.8116097   0.00836384 -1.1193496 ]], Action: 1, Reward: 1.0, Next State: [[-0.01646458  0.8116097   0.00836384 -1.1193496 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 57, State: [[-2.3238534e-04  1.0066209e+00 -1.4023147e-02 -1.4093972e+00]], Action: 1, Reward: 1.0, Next State: [[-2.3238534e-04  1.0066209e+00 -1.4023147e-02 -1.4093972e+00]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 57, State: [[ 0.01990003  1.201914   -0.04221109 -1.7064307 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01990003  1.201914   -0.04221109 -1.7064307 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 57, State: [[ 0.04393831  1.3974953  -0.07633971 -2.0119476 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04393831  1.3974953  -0.07633971 -2.0119476 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 57, State: [[ 0.07188822  1.5933232  -0.11657866 -2.3272562 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07188822  1.5933232  -0.11657866 -2.3272562 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 57, State: [[ 0.10375468  1.7892934  -0.16312379 -2.6534128 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10375468  1.7892934  -0.16312379 -2.6534128 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 57, State: [[ 0.13954055  1.9852198  -0.21619204 -2.991147  ]], Action: 1, Reward: 1.0, Next State: [[ 0.13954055  1.9852198  -0.21619204 -2.991147  ]], Done: True\n","Episode: 57, Total Reward: 10.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 58, State: [[-0.00094318  0.1997514  -0.04579556 -0.26375374]], Action: 1, Reward: 1.0, Next State: [[-0.00094318  0.1997514  -0.04579556 -0.26375374]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 58, State: [[ 0.00305185  0.3954961  -0.05107063 -0.5705221 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00305185  0.3954961  -0.05107063 -0.5705221 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 58, State: [[ 0.01096177  0.59129566 -0.06248107 -0.87884676]], Action: 1, Reward: 1.0, Next State: [[ 0.01096177  0.59129566 -0.06248107 -0.87884676]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 58, State: [[ 0.02278769  0.7872084  -0.08005801 -1.1904999 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02278769  0.7872084  -0.08005801 -1.1904999 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 58, State: [[ 0.03853185  0.98327124 -0.10386801 -1.5071642 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03853185  0.98327124 -0.10386801 -1.5071642 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 58, State: [[ 0.05819728  1.1794881  -0.13401128 -1.8303854 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05819728  1.1794881  -0.13401128 -1.8303854 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 58, State: [[ 0.08178704  1.3758157  -0.170619   -2.161518  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08178704  1.3758157  -0.170619   -2.161518  ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 58, State: [[ 0.10930336  1.5721494  -0.21384937 -2.5016613 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10930336  1.5721494  -0.21384937 -2.5016613 ]], Done: True\n","Episode: 58, Total Reward: 8.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 59, State: [[-0.03808422  0.22555521 -0.04210944 -0.2722559 ]], Action: 1, Reward: 1.0, Next State: [[-0.03808422  0.22555521 -0.04210944 -0.2722559 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 59, State: [[-0.03357311  0.42125192 -0.04755456 -0.5779173 ]], Action: 1, Reward: 1.0, Next State: [[-0.03357311  0.42125192 -0.04755456 -0.5779173 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 59, State: [[-0.02514807  0.617007   -0.0591129  -0.8851937 ]], Action: 1, Reward: 1.0, Next State: [[-0.02514807  0.617007   -0.0591129  -0.8851937 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 59, State: [[-0.01280793  0.81287956 -0.07681677 -1.1958585 ]], Action: 1, Reward: 1.0, Next State: [[-0.01280793  0.81287956 -0.07681677 -1.1958585 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 59, State: [[ 0.00344966  1.0089073  -0.10073394 -1.5115949 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00344966  1.0089073  -0.10073394 -1.5115949 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 59, State: [[ 0.0236278   1.2050948  -0.13096584 -1.83395   ]], Action: 1, Reward: 1.0, Next State: [[ 0.0236278   1.2050948  -0.13096584 -1.83395   ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 59, State: [[ 0.0477297   1.4014001  -0.16764484 -2.1642804 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0477297   1.4014001  -0.16764484 -2.1642804 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 59, State: [[ 0.0757577   1.5977191  -0.21093045 -2.5036874 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0757577   1.5977191  -0.21093045 -2.5036874 ]], Done: True\n","Episode: 59, Total Reward: 8.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 60, State: [[ 0.00216049  0.16778277  0.00405639 -0.28141242]], Action: 1, Reward: 1.0, Next State: [[ 0.00216049  0.16778277  0.00405639 -0.28141242]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 60, State: [[ 0.00551615  0.3628466  -0.00157186 -0.5728132 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00551615  0.3628466  -0.00157186 -0.5728132 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 60, State: [[ 0.01277308  0.55799055 -0.01302813 -0.86599094]], Action: 1, Reward: 1.0, Next State: [[ 0.01277308  0.55799055 -0.01302813 -0.86599094]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 60, State: [[ 0.02393289  0.7532874  -0.03034795 -1.1627414 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02393289  0.7532874  -0.03034795 -1.1627414 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 72ms/step\n","Episode: 60, State: [[ 0.03899864  0.9487911  -0.05360277 -1.464783  ]], Action: 1, Reward: 1.0, Next State: [[ 0.03899864  0.9487911  -0.05360277 -1.464783  ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 60, State: [[ 0.05797446  1.1445271  -0.08289843 -1.7737168 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05797446  1.1445271  -0.08289843 -1.7737168 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 60, State: [[ 0.080865    1.34048    -0.11837277 -2.090981  ]], Action: 1, Reward: 1.0, Next State: [[ 0.080865    1.34048    -0.11837277 -2.090981  ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 55ms/step\n","Episode: 60, State: [[ 0.10767461  1.53658    -0.16019239 -2.4177928 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10767461  1.53658    -0.16019239 -2.4177928 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 60, State: [[ 0.1384062   1.7326853  -0.20854825 -2.7550802 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1384062   1.7326853  -0.20854825 -2.7550802 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 60, State: [[ 0.17305991  1.9285647  -0.26364985 -3.1034026 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17305991  1.9285647  -0.26364985 -3.1034026 ]], Done: True\n","Episode: 60, Total Reward: 10.0\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 61, State: [[ 0.01298955  0.17126715  0.0185023  -0.25982586]], Action: 1, Reward: 1.0, Next State: [[ 0.01298955  0.17126715  0.0185023  -0.25982586]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 57ms/step\n","Episode: 61, State: [[ 0.01641489  0.36612016  0.01330578 -0.54661596]], Action: 1, Reward: 1.0, Next State: [[ 0.01641489  0.36612016  0.01330578 -0.54661596]], Done: False\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 61, State: [[ 0.02373729  0.5610526   0.00237346 -0.83507705]], Action: 1, Reward: 1.0, Next State: [[ 0.02373729  0.5610526   0.00237346 -0.83507705]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 61, State: [[ 0.03495834  0.7561421  -0.01432808 -1.1270126 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03495834  0.7561421  -0.01432808 -1.1270126 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 61, State: [[ 0.05008119  0.9514488  -0.03686833 -1.4241549 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05008119  0.9514488  -0.03686833 -1.4241549 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 61, State: [[ 0.06911016  1.1470066  -0.06535143 -1.7281291 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06911016  1.1470066  -0.06535143 -1.7281291 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 61, State: [[ 0.0920503   1.3428118  -0.09991401 -2.0404096 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0920503   1.3428118  -0.09991401 -2.0404096 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 61, State: [[ 0.11890654  1.5388093  -0.14072222 -2.3622656 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11890654  1.5388093  -0.14072222 -2.3622656 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 61, State: [[ 0.14968272  1.7348771  -0.18796752 -2.694696  ]], Action: 1, Reward: 1.0, Next State: [[ 0.14968272  1.7348771  -0.18796752 -2.694696  ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 61, State: [[ 0.18438026  1.9308074  -0.24186143 -3.0383523 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18438026  1.9308074  -0.24186143 -3.0383523 ]], Done: True\n","Episode: 61, Total Reward: 10.0\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 62, State: [[ 0.00522842  0.227669   -0.01507187 -0.29216206]], Action: 1, Reward: 1.0, Next State: [[ 0.00522842  0.227669   -0.01507187 -0.29216206]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 62, State: [[ 0.0097818   0.42300257 -0.02091511 -0.5895601 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0097818   0.42300257 -0.02091511 -0.5895601 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 62, State: [[ 0.01824185  0.61841106 -0.03270632 -0.8887573 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01824185  0.61841106 -0.03270632 -0.8887573 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 62, State: [[ 0.03061007  0.8139612  -0.05048146 -1.1915396 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03061007  0.8139612  -0.05048146 -1.1915396 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 62, State: [[ 0.04688929  1.0096996  -0.07431225 -1.4996084 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04688929  1.0096996  -0.07431225 -1.4996084 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 62, State: [[ 0.06708328  1.2056414  -0.10430442 -1.8145376 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06708328  1.2056414  -0.10430442 -1.8145376 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 62, State: [[ 0.09119611  1.4017584  -0.14059517 -2.1377244 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09119611  1.4017584  -0.14059517 -2.1377244 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 62, State: [[ 0.11923128  1.5979636  -0.18334965 -2.470327  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11923128  1.5979636  -0.18334965 -2.470327  ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 62, State: [[ 0.15119055  1.794094   -0.2327562  -2.8131948 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15119055  1.794094   -0.2327562  -2.8131948 ]], Done: True\n","Episode: 62, Total Reward: 9.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 63, State: [[-0.00680964  0.14858684 -0.04585285 -0.3191906 ]], Action: 1, Reward: 1.0, Next State: [[-0.00680964  0.14858684 -0.04585285 -0.3191906 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 63, State: [[-0.0038379   0.34433082 -0.05223666 -0.62597394]], Action: 1, Reward: 1.0, Next State: [[-0.0038379   0.34433082 -0.05223666 -0.62597394]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 63, State: [[ 0.00304871  0.5401415  -0.06475614 -0.93464   ]], Action: 1, Reward: 1.0, Next State: [[ 0.00304871  0.5401415  -0.06475614 -0.93464   ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 63, State: [[ 0.01385154  0.7360744  -0.08344894 -1.2469482 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01385154  0.7360744  -0.08344894 -1.2469482 ]], Done: False\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 63, State: [[ 0.02857303  0.93216145 -0.1083879  -1.5645609 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02857303  0.93216145 -0.1083879  -1.5645609 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 63, State: [[ 0.04721626  1.1283994  -0.13967912 -1.888994  ]], Action: 1, Reward: 1.0, Next State: [[ 0.04721626  1.1283994  -0.13967912 -1.888994  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 63, State: [[ 0.06978425  1.3247354  -0.177459   -2.2215621 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06978425  1.3247354  -0.177459   -2.2215621 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 63, State: [[ 0.09627896  1.5210516  -0.22189024 -2.5633113 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09627896  1.5210516  -0.22189024 -2.5633113 ]], Done: True\n","Episode: 63, Total Reward: 8.0\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 64, State: [[ 0.00969888  0.24027324 -0.0242272  -0.2925525 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00969888  0.24027324 -0.0242272  -0.2925525 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 64, State: [[ 0.01450434  0.4357321  -0.03007825 -0.59277683]], Action: 1, Reward: 1.0, Next State: [[ 0.01450434  0.4357321  -0.03007825 -0.59277683]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 64, State: [[ 0.02321898  0.6312619  -0.04193379 -0.8947806 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02321898  0.6312619  -0.04193379 -0.8947806 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 52ms/step\n","Episode: 64, State: [[ 0.03584422  0.82692665 -0.0598294  -1.2003446 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03584422  0.82692665 -0.0598294  -1.2003446 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 64, State: [[ 0.05238275  1.0227693  -0.08383629 -1.5111623 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05238275  1.0227693  -0.08383629 -1.5111623 ]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 64, State: [[ 0.07283814  1.2188008  -0.11405954 -1.8287958 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07283814  1.2188008  -0.11405954 -1.8287958 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 64, State: [[ 0.09721415  1.4149871  -0.15063545 -2.154624  ]], Action: 1, Reward: 1.0, Next State: [[ 0.09721415  1.4149871  -0.15063545 -2.154624  ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 64, State: [[ 0.1255139   1.6112338  -0.19372794 -2.48978   ]], Action: 1, Reward: 1.0, Next State: [[ 0.1255139   1.6112338  -0.19372794 -2.48978   ]], Done: False\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Episode: 64, State: [[ 0.15773857  1.8073689  -0.24352354 -2.8350794 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15773857  1.8073689  -0.24352354 -2.8350794 ]], Done: True\n","Episode: 64, Total Reward: 9.0\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 65, State: [[ 0.00464887  0.15794165  0.03381375 -0.28667396]], Action: 1, Reward: 1.0, Next State: [[ 0.00464887  0.15794165  0.03381375 -0.28667396]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 70ms/step\n","Episode: 65, State: [[ 0.0078077   0.35256547  0.02808027 -0.56850344]], Action: 1, Reward: 1.0, Next State: [[ 0.0078077   0.35256547  0.02808027 -0.56850344]], Done: False\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 65, State: [[ 0.01485901  0.5472826   0.0167102  -0.8522094 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01485901  0.5472826   0.0167102  -0.8522094 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 65, State: [[ 2.5804663e-02  7.4217278e-01 -3.3398508e-04 -1.1395913e+00]], Action: 1, Reward: 1.0, Next State: [[ 2.5804663e-02  7.4217278e-01 -3.3398508e-04 -1.1395913e+00]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 65, State: [[ 0.04064812  0.9372991  -0.02312581 -1.432379  ]], Action: 1, Reward: 1.0, Next State: [[ 0.04064812  0.9372991  -0.02312581 -1.432379  ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 65, State: [[ 0.0593941   1.1326987  -0.05177339 -1.7321984 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0593941   1.1326987  -0.05177339 -1.7321984 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 65, State: [[ 0.08204807  1.3283719  -0.08641735 -2.0405295 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08204807  1.3283719  -0.08641735 -2.0405295 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 65, State: [[ 0.10861551  1.5242697  -0.12722795 -2.3586547 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10861551  1.5242697  -0.12722795 -2.3586547 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 65, State: [[ 0.13910091  1.7202771  -0.17440104 -2.6875937 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13910091  1.7202771  -0.17440104 -2.6875937 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 65, State: [[ 0.17350644  1.9161954  -0.22815292 -3.0280275 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17350644  1.9161954  -0.22815292 -3.0280275 ]], Done: True\n","Episode: 65, Total Reward: 10.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 66, State: [[ 0.03343923  0.23127206 -0.00863596 -0.30247244]], Action: 1, Reward: 1.0, Next State: [[ 0.03343923  0.23127206 -0.00863596 -0.30247244]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 66, State: [[ 0.03806467  0.42651603 -0.01468541 -0.5978664 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03806467  0.42651603 -0.01468541 -0.5978664 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 66, State: [[ 0.04659499  0.62184036 -0.02664274 -0.8951387 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04659499  0.62184036 -0.02664274 -0.8951387 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 66, State: [[ 0.0590318   0.81731325 -0.04454551 -1.196076  ]], Action: 1, Reward: 1.0, Next State: [[ 0.0590318   0.81731325 -0.04454551 -1.196076  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 66, State: [[ 0.07537807  1.0129826  -0.06846703 -1.502381  ]], Action: 1, Reward: 1.0, Next State: [[ 0.07537807  1.0129826  -0.06846703 -1.502381  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 66, State: [[ 0.09563772  1.2088658  -0.09851465 -1.8156308 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09563772  1.2088658  -0.09851465 -1.8156308 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 66, State: [[ 0.11981503  1.4049363  -0.13482727 -2.137227  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11981503  1.4049363  -0.13482727 -2.137227  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 66, State: [[ 0.14791375  1.6011101  -0.1775718  -2.4683366 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14791375  1.6011101  -0.1775718  -2.4683366 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 66, State: [[ 0.17993596  1.7972279  -0.22693853 -2.8098195 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17993596  1.7972279  -0.22693853 -2.8098195 ]], Done: True\n","Episode: 66, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 67, State: [[ 0.03914456  0.1491259   0.02697447 -0.24353051]], Action: 1, Reward: 1.0, Next State: [[ 0.03914456  0.1491259   0.02697447 -0.24353051]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 67, State: [[ 0.04212707  0.3438524   0.02210386 -0.52758443]], Action: 1, Reward: 1.0, Next State: [[ 0.04212707  0.3438524   0.02210386 -0.52758443]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 67, State: [[ 0.04900412  0.5386565   0.01155217 -0.81322116]], Action: 1, Reward: 1.0, Next State: [[ 0.04900412  0.5386565   0.01155217 -0.81322116]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 67, State: [[ 0.05977725  0.7336183  -0.00471225 -1.1022482 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05977725  0.7336183  -0.00471225 -1.1022482 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 67, State: [[ 0.07444962  0.92880195 -0.02675722 -1.3964058 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07444962  0.92880195 -0.02675722 -1.3964058 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 67, State: [[ 0.09302565  1.1242464  -0.05468533 -1.6973331 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09302565  1.1242464  -0.05468533 -1.6973331 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 67, State: [[ 0.11551058  1.3199545  -0.088632   -2.006526  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11551058  1.3199545  -0.088632   -2.006526  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 67, State: [[ 0.14190967  1.515881   -0.12876251 -2.325286  ]], Action: 1, Reward: 1.0, Next State: [[ 0.14190967  1.515881   -0.12876251 -2.325286  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 67, State: [[ 0.1722273   1.7119154  -0.17526823 -2.6546547 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1722273   1.7119154  -0.17526823 -2.6546547 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 67, State: [[ 0.2064656   1.9078649  -0.22836132 -2.9953415 ]], Action: 1, Reward: 1.0, Next State: [[ 0.2064656   1.9078649  -0.22836132 -2.9953415 ]], Done: True\n","Episode: 67, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 68, State: [[-0.0092568   0.2238437   0.01869547 -0.30541655]], Action: 1, Reward: 1.0, Next State: [[-0.0092568   0.2238437   0.01869547 -0.30541655]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 68, State: [[-0.00477993  0.41869432  0.01258714 -0.59214526]], Action: 1, Reward: 1.0, Next State: [[-0.00477993  0.41869432  0.01258714 -0.59214526]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 68, State: [[ 3.5939591e-03  6.1363780e-01  7.4423786e-04 -8.8083678e-01]], Action: 1, Reward: 1.0, Next State: [[ 3.5939591e-03  6.1363780e-01  7.4423786e-04 -8.8083678e-01]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 68, State: [[ 0.01586672  0.8087496  -0.0168725  -1.1732856 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01586672  0.8087496  -0.0168725  -1.1732856 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 68, State: [[ 0.03204171  1.0040869  -0.04033821 -1.47121   ]], Action: 1, Reward: 1.0, Next State: [[ 0.03204171  1.0040869  -0.04033821 -1.47121   ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 68, State: [[ 0.05212344  1.1996782  -0.06976241 -1.7762146 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05212344  1.1996782  -0.06976241 -1.7762146 ]], Done: False\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 49ms/step\n","Episode: 68, State: [[ 0.07611701  1.3955132  -0.1052867  -2.0897462 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07611701  1.3955132  -0.1052867  -2.0897462 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 68, State: [[ 0.10402727  1.5915278  -0.14708163 -2.413037  ]], Action: 1, Reward: 1.0, Next State: [[ 0.10402727  1.5915278  -0.14708163 -2.413037  ]], Done: False\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 68, State: [[ 0.13585784  1.7875882  -0.19534236 -2.7470386 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13585784  1.7875882  -0.19534236 -2.7470386 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 68, State: [[ 0.1716096   1.983472   -0.25028315 -3.0923421 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1716096   1.983472   -0.25028315 -3.0923421 ]], Done: True\n","Episode: 68, Total Reward: 10.0\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 69, State: [[ 0.02588484  0.24133119  0.00215658 -0.33234397]], Action: 1, Reward: 1.0, Next State: [[ 0.02588484  0.24133119  0.00215658 -0.33234397]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 69, State: [[ 0.03071147  0.43642238 -0.0044903  -0.6243461 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03071147  0.43642238 -0.0044903  -0.6243461 ]], Done: False\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 69, State: [[ 0.03943991  0.63160676 -0.01697722 -0.91843975]], Action: 1, Reward: 1.0, Next State: [[ 0.03943991  0.63160676 -0.01697722 -0.91843975]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 69, State: [[ 0.05207205  0.826954   -0.03534602 -1.2164096 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05207205  0.826954   -0.03534602 -1.2164096 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 69, State: [[ 0.06861113  1.0225136  -0.05967421 -1.5199553 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06861113  1.0225136  -0.05967421 -1.5199553 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 47ms/step\n","Episode: 69, State: [[ 0.0890614   1.2183039  -0.09007332 -1.8306519 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0890614   1.2183039  -0.09007332 -1.8306519 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 72ms/step\n","Episode: 69, State: [[ 0.11342748  1.4143006  -0.12668635 -2.1499007 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11342748  1.4143006  -0.12668635 -2.1499007 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 69, State: [[ 0.14171349  1.6104212  -0.16968437 -2.4788704 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14171349  1.6104212  -0.16968437 -2.4788704 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 47ms/step\n","Episode: 69, State: [[ 0.17392191  1.8065087  -0.21926177 -2.8184254 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17392191  1.8065087  -0.21926177 -2.8184254 ]], Done: True\n","Episode: 69, Total Reward: 9.0\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 70, State: [[-0.04167251  0.20818472  0.03024413 -0.2899398 ]], Action: 1, Reward: 1.0, Next State: [[-0.04167251  0.20818472  0.03024413 -0.2899398 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 70, State: [[-0.03750881  0.40286264  0.02444534 -0.5729327 ]], Action: 1, Reward: 1.0, Next State: [[-0.03750881  0.40286264  0.02444534 -0.5729327 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 70, State: [[-0.02945156  0.5976335   0.01298668 -0.85781544]], Action: 1, Reward: 1.0, Next State: [[-0.02945156  0.5976335   0.01298668 -0.85781544]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 70, State: [[-0.01749889  0.79257613 -0.00416963 -1.1463867 ]], Action: 1, Reward: 1.0, Next State: [[-0.01749889  0.79257613 -0.00416963 -1.1463867 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 70, State: [[-0.00164737  0.98775226 -0.02709736 -1.4403744 ]], Action: 1, Reward: 1.0, Next State: [[-0.00164737  0.98775226 -0.02709736 -1.4403744 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 70, State: [[ 0.01810768  1.1831973  -0.05590485 -1.7413999 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01810768  1.1831973  -0.05590485 -1.7413999 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 70, State: [[ 0.04177162  1.3789093  -0.09073284 -2.0509367 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04177162  1.3789093  -0.09073284 -2.0509367 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 70, State: [[ 0.06934981  1.5748359  -0.13175158 -2.3702567 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06934981  1.5748359  -0.13175158 -2.3702567 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 70, State: [[ 0.10084653  1.7708579  -0.1791567  -2.7003644 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10084653  1.7708579  -0.1791567  -2.7003644 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 70, State: [[ 0.13626368  1.9667717  -0.233164   -3.041922  ]], Action: 1, Reward: 1.0, Next State: [[ 0.13626368  1.9667717  -0.233164   -3.041922  ]], Done: True\n","Episode: 70, Total Reward: 10.0\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 71, State: [[-0.04945972  0.16882776 -0.01662334 -0.29421008]], Action: 1, Reward: 1.0, Next State: [[-0.04945972  0.16882776 -0.01662334 -0.29421008]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 71, State: [[-0.04608316  0.3641827  -0.02250754 -0.59208906]], Action: 1, Reward: 1.0, Next State: [[-0.04608316  0.3641827  -0.02250754 -0.59208906]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 71, State: [[-0.03879951  0.5596124  -0.03434933 -0.891776  ]], Action: 1, Reward: 1.0, Next State: [[-0.03879951  0.5596124  -0.03434933 -0.891776  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 71, State: [[-0.02760726  0.75518304 -0.05218485 -1.1950557 ]], Action: 1, Reward: 1.0, Next State: [[-0.02760726  0.75518304 -0.05218485 -1.1950557 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 71, State: [[-0.0125036   0.95094043 -0.07608596 -1.5036273 ]], Action: 1, Reward: 1.0, Next State: [[-0.0125036   0.95094043 -0.07608596 -1.5036273 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 71, State: [[ 0.00651521  1.1468989  -0.1061585  -1.8190622 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00651521  1.1468989  -0.1061585  -1.8190622 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 71, State: [[ 0.02945318  1.3430287  -0.14253975 -2.142753  ]], Action: 1, Reward: 1.0, Next State: [[ 0.02945318  1.3430287  -0.14253975 -2.142753  ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 71, State: [[ 0.05631376  1.5392412  -0.18539481 -2.4758518 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05631376  1.5392412  -0.18539481 -2.4758518 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Episode: 71, State: [[ 0.08709858  1.7353715  -0.23491184 -2.8192    ]], Action: 1, Reward: 1.0, Next State: [[ 0.08709858  1.7353715  -0.23491184 -2.8192    ]], Done: True\n","Episode: 71, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 72, State: [[ 0.04589119  0.15580253 -0.03169124 -0.33884615]], Action: 1, Reward: 1.0, Next State: [[ 0.04589119  0.15580253 -0.03169124 -0.33884615]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 72, State: [[ 0.04900724  0.35136077 -0.03846816 -0.6413519 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04900724  0.35136077 -0.03846816 -0.6413519 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 72, State: [[ 0.05603446  0.54699725 -0.0512952  -0.9458964 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05603446  0.54699725 -0.0512952  -0.9458964 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 72, State: [[ 0.0669744   0.74277115 -0.07021313 -1.2542452 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0669744   0.74277115 -0.07021313 -1.2542452 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Episode: 72, State: [[ 0.08182982  0.9387185  -0.09529803 -1.5680677 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08182982  0.9387185  -0.09529803 -1.5680677 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 72, State: [[ 0.1006042   1.1348407  -0.12665938 -1.8888913 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1006042   1.1348407  -0.12665938 -1.8888913 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 72, State: [[ 0.12330101  1.3310909  -0.1644372  -2.218047  ]], Action: 1, Reward: 1.0, Next State: [[ 0.12330101  1.3310909  -0.1644372  -2.218047  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 72, State: [[ 0.14992283  1.5273583  -0.20879816 -2.5566037 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14992283  1.5273583  -0.20879816 -2.5566037 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 72, State: [[ 0.18046999  1.7234502  -0.25993022 -2.9052947 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18046999  1.7234502  -0.25993022 -2.9052947 ]], Done: True\n","Episode: 72, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 73, State: [[-0.02290394  0.19004063  0.03776106 -0.31925547]], Action: 1, Reward: 1.0, Next State: [[-0.02290394  0.19004063  0.03776106 -0.31925547]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 73, State: [[-0.01910313  0.38460502  0.03137595 -0.59979486]], Action: 1, Reward: 1.0, Next State: [[-0.01910313  0.38460502  0.03137595 -0.59979486]], Done: False\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 73, State: [[-0.01141103  0.5792743   0.01938006 -0.88243204]], Action: 1, Reward: 1.0, Next State: [[-0.01141103  0.5792743   0.01938006 -0.88243204]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 73, State: [[ 1.7445524e-04  7.7412772e-01  1.7314146e-03 -1.1689600e+00]], Action: 1, Reward: 1.0, Next State: [[ 1.7445524e-04  7.7412772e-01  1.7314146e-03 -1.1689600e+00]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 73, State: [[ 0.01565701  0.96922714 -0.02164778 -1.4610995 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01565701  0.96922714 -0.02164778 -1.4610995 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 73, State: [[ 0.03504155  1.1646076  -0.05086977 -1.7604656 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03504155  1.1646076  -0.05086977 -1.7604656 ]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 73, State: [[ 0.05833371  1.3602672  -0.08607909 -2.0685244 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05833371  1.3602672  -0.08607909 -2.0685244 ]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 54ms/step\n","Episode: 73, State: [[ 0.08553905  1.5561527  -0.12744957 -2.386541  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08553905  1.5561527  -0.12744957 -2.386541  ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 73, State: [[ 0.1166621   1.7521447  -0.17518039 -2.7155132 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1166621   1.7521447  -0.17518039 -2.7155132 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 78ms/step\n","Episode: 73, State: [[ 0.151705    1.9480387  -0.22949065 -3.056097  ]], Action: 1, Reward: 1.0, Next State: [[ 0.151705    1.9480387  -0.22949065 -3.056097  ]], Done: True\n","Episode: 73, Total Reward: 10.0\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 74, State: [[-0.01755377  0.20735313  0.02363534 -0.29637843]], Action: 1, Reward: 1.0, Next State: [[-0.01755377  0.20735313  0.02363534 -0.29637843]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 74, State: [[-0.01340671  0.4021303   0.01770777 -0.5815145 ]], Action: 1, Reward: 1.0, Next State: [[-0.01340671  0.4021303   0.01770777 -0.5815145 ]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 70ms/step\n","Episode: 74, State: [[-0.00536411  0.5969997   0.00607748 -0.86856693]], Action: 1, Reward: 1.0, Next State: [[-0.00536411  0.5969997   0.00607748 -0.86856693]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 47ms/step\n","Episode: 74, State: [[ 0.00657589  0.7920385  -0.01129386 -1.1593329 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00657589  0.7920385  -0.01129386 -1.1593329 ]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 74, State: [[ 0.02241666  0.98730576 -0.03448051 -1.4555354 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02241666  0.98730576 -0.03448051 -1.4555354 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 74, State: [[ 0.04216277  1.1828336  -0.06359122 -1.7587881 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04216277  1.1828336  -0.06359122 -1.7587881 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 74, State: [[ 0.06581944  1.3786154  -0.09876698 -2.0705504 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06581944  1.3786154  -0.09876698 -2.0705504 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 74, State: [[ 0.09339175  1.5745927  -0.140178   -2.392074  ]], Action: 1, Reward: 1.0, Next State: [[ 0.09339175  1.5745927  -0.140178   -2.392074  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 74, State: [[ 0.12488361  1.7706388  -0.18801948 -2.7243364 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12488361  1.7706388  -0.18801948 -2.7243364 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 74, State: [[ 0.16029638  1.96654    -0.2425062  -3.067962  ]], Action: 1, Reward: 1.0, Next State: [[ 0.16029638  1.96654    -0.2425062  -3.067962  ]], Done: True\n","Episode: 74, Total Reward: 10.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 75, State: [[-0.01251715  0.22727922 -0.0111578  -0.30643663]], Action: 1, Reward: 1.0, Next State: [[-0.01251715  0.22727922 -0.0111578  -0.30643663]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 75, State: [[-0.00797157  0.42255837 -0.01728653 -0.60261744]], Action: 1, Reward: 1.0, Next State: [[-0.00797157  0.42255837 -0.01728653 -0.60261744]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 75, State: [[ 4.7959748e-04  6.1791778e-01 -2.9338883e-02 -9.0069479e-01]], Action: 1, Reward: 1.0, Next State: [[ 4.7959748e-04  6.1791778e-01 -2.9338883e-02 -9.0069479e-01]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 75, State: [[ 0.01283795  0.81342477 -0.04735278 -1.2024534 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01283795  0.81342477 -0.04735278 -1.2024534 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 75, State: [[ 0.02910645  1.009126   -0.07140185 -1.5095927 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02910645  1.009126   -0.07140185 -1.5095927 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 75, State: [[ 0.04928897  1.2050369  -0.1015937  -1.8236846 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04928897  1.2050369  -0.1015937  -1.8236846 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 75, State: [[ 0.0733897  1.4011291 -0.1380674 -2.1461234]], Action: 1, Reward: 1.0, Next State: [[ 0.0733897  1.4011291 -0.1380674 -2.1461234]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 75, State: [[ 0.10141229  1.5973158  -0.18098986 -2.478066  ]], Action: 1, Reward: 1.0, Next State: [[ 0.10141229  1.5973158  -0.18098986 -2.478066  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 75, State: [[ 0.1333586   1.7934337  -0.23055118 -2.8203588 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1333586   1.7934337  -0.23055118 -2.8203588 ]], Done: True\n","Episode: 75, Total Reward: 9.0\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 76, State: [[ 0.02640963  0.21335815  0.00476182 -0.27071017]], Action: 1, Reward: 1.0, Next State: [[ 0.02640963  0.21335815  0.00476182 -0.27071017]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 76, State: [[ 0.0306768   0.40841183 -0.00065238 -0.5618874 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0306768   0.40841183 -0.00065238 -0.5618874 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 76, State: [[ 0.03884503  0.6035429  -0.01189013 -0.8547758 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03884503  0.6035429  -0.01189013 -0.8547758 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 76, State: [[ 0.05091589  0.7988249  -0.02898565 -1.1511737 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05091589  0.7988249  -0.02898565 -1.1511737 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 76, State: [[ 0.06689239  0.9943128  -0.05200912 -1.452803  ]], Action: 1, Reward: 1.0, Next State: [[ 0.06689239  0.9943128  -0.05200912 -1.452803  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 76, State: [[ 0.08677864  1.1900336  -0.08106518 -1.7612709 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08677864  1.1900336  -0.08106518 -1.7612709 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 76, State: [[ 0.11057931  1.3859739  -0.1162906  -2.0780234 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11057931  1.3859739  -0.1162906  -2.0780234 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 76, State: [[ 0.1382988   1.5820667  -0.15785107 -2.4042883 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1382988   1.5820667  -0.15785107 -2.4042883 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 76, State: [[ 0.16994013  1.7781739  -0.20593683 -2.7410076 ]], Action: 1, Reward: 1.0, Next State: [[ 0.16994013  1.7781739  -0.20593683 -2.7410076 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 76, State: [[ 0.20550361  1.9740683  -0.26075697 -3.0887587 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20550361  1.9740683  -0.26075697 -3.0887587 ]], Done: True\n","Episode: 76, Total Reward: 10.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 77, State: [[-0.01056369  0.16666608 -0.00883652 -0.32398605]], Action: 1, Reward: 1.0, Next State: [[-0.01056369  0.16666608 -0.00883652 -0.32398605]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 77, State: [[-0.00723037  0.36191273 -0.01531625 -0.6194425 ]], Action: 1, Reward: 1.0, Next State: [[-0.00723037  0.36191273 -0.01531625 -0.6194425 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 77, State: [[ 7.8814201e-06  5.5724519e-01 -2.7705094e-02 -9.1690964e-01]], Action: 1, Reward: 1.0, Next State: [[ 7.8814201e-06  5.5724519e-01 -2.7705094e-02 -9.1690964e-01]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 77, State: [[ 0.01115279  0.7527306  -0.04604329 -1.2181695 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01115279  0.7527306  -0.04604329 -1.2181695 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 55ms/step\n","Episode: 77, State: [[ 0.0262074   0.948415   -0.07040668 -1.5249169 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0262074   0.948415   -0.07040668 -1.5249169 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 60ms/step\n","Episode: 77, State: [[ 0.0451757   1.1443127  -0.10090502 -1.838718  ]], Action: 1, Reward: 1.0, Next State: [[ 0.0451757   1.1443127  -0.10090502 -1.838718  ]], Done: False\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 77, State: [[ 0.06806196  1.3403943  -0.13767938 -2.16096   ]], Action: 1, Reward: 1.0, Next State: [[ 0.06806196  1.3403943  -0.13767938 -2.16096   ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 52ms/step\n","Episode: 77, State: [[ 0.09486984  1.5365702  -0.18089858 -2.4927893 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09486984  1.5365702  -0.18089858 -2.4927893 ]], Done: False\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 77, State: [[ 0.12560125  1.7326751  -0.23075436 -2.8350413 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12560125  1.7326751  -0.23075436 -2.8350413 ]], Done: True\n","Episode: 77, Total Reward: 9.0\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 78, State: [[-0.00054332  0.18414593  0.03030311 -0.3304966 ]], Action: 1, Reward: 1.0, Next State: [[-0.00054332  0.18414593  0.03030311 -0.3304966 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 47ms/step\n","Episode: 78, State: [[ 0.0031396   0.37882373  0.02369318 -0.61347145]], Action: 1, Reward: 1.0, Next State: [[ 0.0031396   0.37882373  0.02369318 -0.61347145]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 78, State: [[ 0.01071608  0.57360667  0.01142375 -0.8985988 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01071608  0.57360667  0.01142375 -0.8985988 ]], Done: False\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 78, State: [[ 0.02218821  0.768572   -0.00654823 -1.1876692 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02218821  0.768572   -0.00654823 -1.1876692 ]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 78, State: [[ 0.03755965  0.9637782  -0.03030161 -1.4823973 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03755965  0.9637782  -0.03030161 -1.4823973 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 78, State: [[ 0.05683521  1.1592563  -0.05994955 -1.7843874 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05683521  1.1592563  -0.05994955 -1.7843874 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 70ms/step\n","Episode: 78, State: [[ 0.08002034  1.3549985  -0.0956373  -2.0950878 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08002034  1.3549985  -0.0956373  -2.0950878 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 78, State: [[ 0.10712031  1.550944   -0.13753906 -2.4157374 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10712031  1.550944   -0.13753906 -2.4157374 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 78, State: [[ 0.13813919  1.7469635  -0.1858538  -2.747299  ]], Action: 1, Reward: 1.0, Next State: [[ 0.13813919  1.7469635  -0.1858538  -2.747299  ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 78, State: [[ 0.17307846  1.9428399  -0.24079978 -3.0903807 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17307846  1.9428399  -0.24079978 -3.0903807 ]], Done: True\n","Episode: 78, Total Reward: 10.0\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 79, State: [[-0.02697738  0.20008318 -0.00847344 -0.31064665]], Action: 1, Reward: 1.0, Next State: [[-0.02697738  0.20008318 -0.00847344 -0.31064665]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 79, State: [[-0.02297572  0.39532483 -0.01468637 -0.60598975]], Action: 1, Reward: 1.0, Next State: [[-0.02297572  0.39532483 -0.01468637 -0.60598975]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 79, State: [[-0.01506922  0.590649   -0.02680617 -0.90326214]], Action: 1, Reward: 1.0, Next State: [[-0.01506922  0.590649   -0.02680617 -0.90326214]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 79, State: [[-0.00325624  0.78612363 -0.04487141 -1.2042488 ]], Action: 1, Reward: 1.0, Next State: [[-0.00325624  0.78612363 -0.04487141 -1.2042488 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Episode: 79, State: [[ 0.01246623  0.98179597 -0.06895638 -1.5106496 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01246623  0.98179597 -0.06895638 -1.5106496 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 79, State: [[ 0.03210215  1.1776823  -0.09916937 -1.8240378 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03210215  1.1776823  -0.09916937 -1.8240378 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Episode: 79, State: [[ 0.0556558   1.3737551  -0.13565013 -2.1458101 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0556558   1.3737551  -0.13565013 -2.1458101 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 79, State: [[ 0.0831309   1.5699288  -0.17856634 -2.4771264 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0831309   1.5699288  -0.17856634 -2.4771264 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 79, State: [[ 0.11452947  1.7660414  -0.22810887 -2.818838  ]], Action: 1, Reward: 1.0, Next State: [[ 0.11452947  1.7660414  -0.22810887 -2.818838  ]], Done: True\n","Episode: 79, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 80, State: [[-0.03758943  0.2011264  -0.0044187  -0.2688802 ]], Action: 1, Reward: 1.0, Next State: [[-0.03758943  0.2011264  -0.0044187  -0.2688802 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 80, State: [[-0.0335669   0.39631113 -0.0097963  -0.56295353]], Action: 1, Reward: 1.0, Next State: [[-0.0335669   0.39631113 -0.0097963  -0.56295353]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 80, State: [[-0.02564068  0.5915692  -0.02105537 -0.8587066 ]], Action: 1, Reward: 1.0, Next State: [[-0.02564068  0.5915692  -0.02105537 -0.8587066 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 80, State: [[-0.01380929  0.7869715  -0.0382295  -1.1579349 ]], Action: 1, Reward: 1.0, Next State: [[-0.01380929  0.7869715  -0.0382295  -1.1579349 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Episode: 80, State: [[ 0.00193014  0.9825703  -0.0613882  -1.4623555 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00193014  0.9825703  -0.0613882  -1.4623555 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Episode: 80, State: [[ 0.02158154  1.1783885  -0.09063531 -1.7735664 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02158154  1.1783885  -0.09063531 -1.7735664 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 80, State: [[ 0.04514932  1.3744079  -0.12610663 -2.092999  ]], Action: 1, Reward: 1.0, Next State: [[ 0.04514932  1.3744079  -0.12610663 -2.092999  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 80, State: [[ 0.07263748  1.5705547  -0.16796662 -2.42186   ]], Action: 1, Reward: 1.0, Next State: [[ 0.07263748  1.5705547  -0.16796662 -2.42186   ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 80, State: [[ 0.10404857  1.7666829  -0.21640381 -2.7610621 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10404857  1.7666829  -0.21640381 -2.7610621 ]], Done: True\n","Episode: 80, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 81, State: [[-0.04335151  0.20613576  0.02159276 -0.25890192]], Action: 1, Reward: 1.0, Next State: [[-0.04335151  0.20613576  0.02159276 -0.25890192]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 81, State: [[-0.03922879  0.4009429   0.01641472 -0.54469675]], Action: 1, Reward: 1.0, Next State: [[-0.03922879  0.4009429   0.01641472 -0.54469675]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 81, State: [[-0.03120994  0.5958304   0.00552078 -0.8321629 ]], Action: 1, Reward: 1.0, Next State: [[-0.03120994  0.5958304   0.00552078 -0.8321629 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 81, State: [[-0.01929333  0.79087645 -0.01112247 -1.1231045 ]], Action: 1, Reward: 1.0, Next State: [[-0.01929333  0.79087645 -0.01112247 -1.1231045 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 81, State: [[-0.0034758   0.98614246 -0.03358456 -1.4192553 ]], Action: 1, Reward: 1.0, Next State: [[-0.0034758   0.98614246 -0.03358456 -1.4192553 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 81, State: [[ 0.01624705  1.1816636  -0.06196967 -1.7222435 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01624705  1.1816636  -0.06196967 -1.7222435 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 81, State: [[ 0.03988032  1.3774378  -0.09641454 -2.0335486 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03988032  1.3774378  -0.09641454 -2.0335486 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 81, State: [[ 0.06742908  1.5734127  -0.13708551 -2.3544476 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06742908  1.5734127  -0.13708551 -2.3544476 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 81, State: [[ 0.09889733  1.7694691  -0.18417446 -2.6859505 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09889733  1.7694691  -0.18417446 -2.6859505 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 81, State: [[ 0.13428672  1.9654033  -0.23789348 -3.0287228 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13428672  1.9654033  -0.23789348 -3.0287228 ]], Done: True\n","Episode: 81, Total Reward: 10.0\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 46ms/step\n","Episode: 82, State: [[-0.01836958  0.18331757  0.02962216 -0.2742531 ]], Action: 1, Reward: 1.0, Next State: [[-0.01836958  0.18331757  0.02962216 -0.2742531 ]], Done: False\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 48ms/step\n","Episode: 82, State: [[-0.01470323  0.37800464  0.0241371  -0.5574479 ]], Action: 1, Reward: 1.0, Next State: [[-0.01470323  0.37800464  0.0241371  -0.5574479 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 82, State: [[-0.00714313  0.57277954  0.01298814 -0.84242964]], Action: 1, Reward: 1.0, Next State: [[-0.00714313  0.57277954  0.01298814 -0.84242964]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 82, State: [[ 0.00431246  0.76772183 -0.00386045 -1.131     ]], Action: 1, Reward: 1.0, Next State: [[ 0.00431246  0.76772183 -0.00386045 -1.131     ]], Done: False\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 82, State: [[ 0.0196669   0.96289414 -0.02648045 -1.4248912 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0196669   0.96289414 -0.02648045 -1.4248912 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 82, State: [[ 0.03892478  1.1583332  -0.05497828 -1.7257314 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03892478  1.1583332  -0.05497828 -1.7257314 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 43ms/step\n","Episode: 82, State: [[ 0.06209144  1.3540392  -0.0894929  -2.0350022 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06209144  1.3540392  -0.0894929  -2.0350022 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 47ms/step\n","Episode: 82, State: [[ 0.08917222  1.5499622  -0.13019295 -2.3539865 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08917222  1.5499622  -0.13019295 -2.3539865 ]], Done: False\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 82, State: [[ 0.12017146  1.7459866  -0.17727268 -2.6837034 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12017146  1.7459866  -0.17727268 -2.6837034 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Episode: 82, State: [[ 0.1550912   1.941913   -0.23094675 -3.024833  ]], Action: 1, Reward: 1.0, Next State: [[ 0.1550912   1.941913   -0.23094675 -3.024833  ]], Done: True\n","Episode: 82, Total Reward: 10.0\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 83, State: [[-0.03553069  0.16421618  0.04669625 -0.2934774 ]], Action: 1, Reward: 1.0, Next State: [[-0.03553069  0.16421618  0.04669625 -0.2934774 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 64ms/step\n","Episode: 83, State: [[-0.03224637  0.35864234  0.0408267  -0.57107496]], Action: 1, Reward: 1.0, Next State: [[-0.03224637  0.35864234  0.0408267  -0.57107496]], Done: False\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 83, State: [[-0.02507352  0.5531687   0.0294052  -0.8506217 ]], Action: 1, Reward: 1.0, Next State: [[-0.02507352  0.5531687   0.0294052  -0.8506217 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 83, State: [[-0.01401015  0.7478776   0.01239276 -1.133915  ]], Action: 1, Reward: 1.0, Next State: [[-0.01401015  0.7478776   0.01239276 -1.133915  ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 83, State: [[ 9.4740489e-04  9.4283521e-01 -1.0285535e-02 -1.4226855e+00]], Action: 1, Reward: 1.0, Next State: [[ 9.4740489e-04  9.4283521e-01 -1.0285535e-02 -1.4226855e+00]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 83, State: [[ 0.01980411  1.1380829  -0.03873925 -1.7185653 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01980411  1.1380829  -0.03873925 -1.7185653 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 83, State: [[ 0.04256577  1.3336267  -0.07311055 -2.0230477 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04256577  1.3336267  -0.07311055 -2.0230477 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 83, State: [[ 0.0692383  1.5294254 -0.1135715 -2.3374364]], Action: 1, Reward: 1.0, Next State: [[ 0.0692383  1.5294254 -0.1135715 -2.3374364]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 83, State: [[ 0.09982681  1.725374   -0.16032022 -2.6627839 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09982681  1.725374   -0.16032022 -2.6627839 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 83, State: [[ 0.13433428  1.9212863  -0.2135759  -2.9998164 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13433428  1.9212863  -0.2135759  -2.9998164 ]], Done: True\n","Episode: 83, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 84, State: [[-0.011498    0.15488842 -0.01213964 -0.30321413]], Action: 1, Reward: 1.0, Next State: [[-0.011498    0.15488842 -0.01213964 -0.30321413]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 84, State: [[-0.00840023  0.35018125 -0.01820393 -0.59970075]], Action: 1, Reward: 1.0, Next State: [[-0.00840023  0.35018125 -0.01820393 -0.59970075]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 84, State: [[-0.0013966   0.5455531  -0.03019794 -0.89806163]], Action: 1, Reward: 1.0, Next State: [[-0.0013966   0.5455531  -0.03019794 -0.89806163]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 84, State: [[ 0.00951446  0.74107105 -0.04815917 -1.2000817 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00951446  0.74107105 -0.04815917 -1.2000817 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 84, State: [[ 0.02433588  0.9367818  -0.07216081 -1.5074607 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02433588  0.9367818  -0.07216081 -1.5074607 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 84, State: [[ 0.04307152  1.1327007  -0.10231002 -1.8217711 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04307152  1.1327007  -0.10231002 -1.8217711 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 84, State: [[ 0.06572553  1.3287994  -0.13874544 -2.1444077 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06572553  1.3287994  -0.13874544 -2.1444077 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Episode: 84, State: [[ 0.09230152  1.5249907  -0.1816336  -2.476527  ]], Action: 1, Reward: 1.0, Next State: [[ 0.09230152  1.5249907  -0.1816336  -2.476527  ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 84, State: [[ 0.12280133  1.7211114  -0.23116414 -2.8189762 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12280133  1.7211114  -0.23116414 -2.8189762 ]], Done: True\n","Episode: 84, Total Reward: 9.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 85, State: [[-0.01193198  0.24284515 -0.0206993  -0.26326478]], Action: 1, Reward: 1.0, Next State: [[-0.01193198  0.24284515 -0.0206993  -0.26326478]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 85, State: [[-0.00707508  0.43825635 -0.0259646  -0.5624039 ]], Action: 1, Reward: 1.0, Next State: [[-0.00707508  0.43825635 -0.0259646  -0.5624039 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 85, State: [[ 0.00169005  0.63373286 -0.03721268 -0.8631526 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00169005  0.63373286 -0.03721268 -0.8631526 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 85, State: [[ 0.0143647   0.8293412  -0.05447573 -1.1672999 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0143647   0.8293412  -0.05447573 -1.1672999 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Episode: 85, State: [[ 0.03095153  1.025128   -0.07782173 -1.4765524 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03095153  1.025128   -0.07782173 -1.4765524 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 85, State: [[ 0.05145409  1.2211095  -0.10735278 -1.7924914 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05145409  1.2211095  -0.10735278 -1.7924914 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 85, State: [[ 0.07587627  1.4172585  -0.1432026  -2.1165226 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07587627  1.4172585  -0.1432026  -2.1165226 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 85, State: [[ 0.10422145  1.6134901  -0.18553306 -2.4498146 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10422145  1.6134901  -0.18553306 -2.4498146 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 85, State: [[ 0.13649125  1.8096437  -0.23452935 -2.7932298 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13649125  1.8096437  -0.23452935 -2.7932298 ]], Done: True\n","Episode: 85, Total Reward: 9.0\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 86, State: [[ 0.03732932  0.19407992 -0.01362304 -0.28644222]], Action: 1, Reward: 1.0, Next State: [[ 0.03732932  0.19407992 -0.01362304 -0.28644222]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 52ms/step\n","Episode: 86, State: [[ 0.04121092  0.38939348 -0.01935189 -0.5833904 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04121092  0.38939348 -0.01935189 -0.5833904 ]], Done: False\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 75ms/step\n","Episode: 86, State: [[ 0.04899879  0.5847811  -0.0310197  -0.8821061 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04899879  0.5847811  -0.0310197  -0.8821061 ]], Done: False\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 50ms/step\n","Episode: 86, State: [[ 0.06069442  0.78031033 -0.04866182 -1.1843772 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06069442  0.78031033 -0.04866182 -1.1843772 ]], Done: False\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 86, State: [[ 0.07630062  0.9760286  -0.07234936 -1.491908  ]], Action: 1, Reward: 1.0, Next State: [[ 0.07630062  0.9760286  -0.07234936 -1.491908  ]], Done: False\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 86, State: [[ 0.09582119  1.1719527  -0.10218752 -1.8062774 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09582119  1.1719527  -0.10218752 -1.8062774 ]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 86ms/step\n","Episode: 86, State: [[ 0.11926024  1.3680559  -0.13831307 -2.1288886 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11926024  1.3680559  -0.13831307 -2.1288886 ]], Done: False\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 63ms/step\n","Episode: 86, State: [[ 0.14662136  1.5642538  -0.18089084 -2.4609094 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14662136  1.5642538  -0.18089084 -2.4609094 ]], Done: False\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 86, State: [[ 0.17790644  1.7603863  -0.23010904 -2.8032005 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17790644  1.7603863  -0.23010904 -2.8032005 ]], Done: True\n","Episode: 86, Total Reward: 9.0\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 87, State: [[-0.04342554  0.19797815  0.04050319 -0.24941923]], Action: 1, Reward: 1.0, Next State: [[-0.04342554  0.19797815  0.04050319 -0.24941923]], Done: False\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 69ms/step\n","Episode: 87, State: [[-0.03946598  0.39249897  0.0355148  -0.5290565 ]], Action: 1, Reward: 1.0, Next State: [[-0.03946598  0.39249897  0.0355148  -0.5290565 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 50ms/step\n","Episode: 87, State: [[-0.031616    0.5871038   0.02493367 -0.81034046]], Action: 1, Reward: 1.0, Next State: [[-0.031616    0.5871038   0.02493367 -0.81034046]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 87, State: [[-0.01987392  0.7818754   0.00872686 -1.0950774 ]], Action: 1, Reward: 1.0, Next State: [[-0.01987392  0.7818754   0.00872686 -1.0950774 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 87, State: [[-0.00423642  0.9768813  -0.01317468 -1.3850094 ]], Action: 1, Reward: 1.0, Next State: [[-0.00423642  0.9768813  -0.01317468 -1.3850094 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 87, State: [[ 0.01530121  1.172165   -0.04087487 -1.6817828 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01530121  1.172165   -0.04087487 -1.6817828 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 87, State: [[ 0.03874451  1.3677359  -0.07451053 -1.986908  ]], Action: 1, Reward: 1.0, Next State: [[ 0.03874451  1.3677359  -0.07451053 -1.986908  ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 87, State: [[ 0.06609923  1.5635564  -0.11424869 -2.3017094 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06609923  1.5635564  -0.11424869 -2.3017094 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 87, State: [[ 0.09737036  1.7595271  -0.16028288 -2.6272652 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09737036  1.7595271  -0.16028288 -2.6272652 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 87, State: [[ 0.1325609   1.9554685  -0.21282819 -2.9643319 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1325609   1.9554685  -0.21282819 -2.9643319 ]], Done: True\n","Episode: 87, Total Reward: 10.0\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 88, State: [[ 0.03362178  0.1569014   0.04524154 -0.2394804 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03362178  0.1569014   0.04524154 -0.2394804 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 88, State: [[ 0.03675981  0.35134885  0.04045193 -0.5175566 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03675981  0.35134885  0.04045193 -0.5175566 ]], Done: False\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 88, State: [[ 0.04378679  0.5458786   0.0301008  -0.7972229 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04378679  0.5458786   0.0301008  -0.7972229 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 88, State: [[ 0.05470436  0.74057484  0.01415634 -1.0802867 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05470436  0.74057484  0.01415634 -1.0802867 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 88, State: [[ 0.06951585  0.93550706 -0.0074494  -1.3684939 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06951585  0.93550706 -0.0074494  -1.3684939 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 88, State: [[ 0.088226    1.1307214  -0.03481928 -1.6634974 ]], Action: 1, Reward: 1.0, Next State: [[ 0.088226    1.1307214  -0.03481928 -1.6634974 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 88, State: [[ 0.11084042  1.326231   -0.06808922 -1.9668189 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11084042  1.326231   -0.06808922 -1.9668189 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 88, State: [[ 0.13736504  1.5220034  -0.1074256  -2.2797997 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13736504  1.5220034  -0.1074256  -2.2797997 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 88, State: [[ 0.16780512  1.7179457  -0.1530216  -2.6035414 ]], Action: 1, Reward: 1.0, Next State: [[ 0.16780512  1.7179457  -0.1530216  -2.6035414 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 88, State: [[ 0.20216402  1.9138869  -0.20509242 -2.9388318 ]], Action: 1, Reward: 1.0, Next State: [[ 0.20216402  1.9138869  -0.20509242 -2.9388318 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 88, State: [[ 0.24044177  2.1095586  -0.26386905 -3.2860634 ]], Action: 1, Reward: 1.0, Next State: [[ 0.24044177  2.1095586  -0.26386905 -3.2860634 ]], Done: True\n","Episode: 88, Total Reward: 11.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 89, State: [[ 0.0286715   0.22163004  0.00793959 -0.26375654]], Action: 1, Reward: 1.0, Next State: [[ 0.0286715   0.22163004  0.00793959 -0.26375654]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 89, State: [[ 0.03310411  0.41663778  0.00266446 -0.5539247 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03310411  0.41663778  0.00266446 -0.5539247 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 89, State: [[ 0.04143686  0.61172223 -0.00841404 -0.84576696]], Action: 1, Reward: 1.0, Next State: [[ 0.04143686  0.61172223 -0.00841404 -0.84576696]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 89, State: [[ 0.0536713   0.80695796 -0.02532937 -1.1410838 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0536713   0.80695796 -0.02532937 -1.1410838 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 89, State: [[ 0.06981046  1.0024016  -0.04815105 -1.4416014 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06981046  1.0024016  -0.04815105 -1.4416014 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 89, State: [[ 0.08985849  1.1980823  -0.07698308 -1.7489332 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08985849  1.1980823  -0.07698308 -1.7489332 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 89, State: [[ 0.11382014  1.3939897  -0.11196174 -2.0645347 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11382014  1.3939897  -0.11196174 -2.0645347 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 89, State: [[ 0.14169994  1.5900602  -0.15325244 -2.389647  ]], Action: 1, Reward: 1.0, Next State: [[ 0.14169994  1.5900602  -0.15325244 -2.389647  ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 50ms/step\n","Episode: 89, State: [[ 0.17350115  1.786161   -0.20104538 -2.7252307 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17350115  1.786161   -0.20104538 -2.7252307 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 89, State: [[ 0.20922436  1.9820706  -0.25555    -3.071886  ]], Action: 1, Reward: 1.0, Next State: [[ 0.20922436  1.9820706  -0.25555    -3.071886  ]], Done: True\n","Episode: 89, Total Reward: 10.0\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 90, State: [[-0.00961569  0.22544634  0.0117655  -0.33370745]], Action: 1, Reward: 1.0, Next State: [[-0.00961569  0.22544634  0.0117655  -0.33370745]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 90, State: [[-0.00510676  0.4203989   0.00509135 -0.622657  ]], Action: 1, Reward: 1.0, Next State: [[-0.00510676  0.4203989   0.00509135 -0.622657  ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 90, State: [[ 0.00330121  0.61544937 -0.00736179 -0.9137321 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00330121  0.61544937 -0.00736179 -0.9137321 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 90, State: [[ 0.0156102   0.81067014 -0.02563643 -1.2087196 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0156102   0.81067014 -0.02563643 -1.2087196 ]], Done: False\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 90, State: [[ 0.03182361  1.0061136  -0.04981082 -1.5093249 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03182361  1.0061136  -0.04981082 -1.5093249 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 90, State: [[ 0.05194588  1.2018026  -0.07999732 -1.8171326 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05194588  1.2018026  -0.07999732 -1.8171326 ]], Done: False\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 90, State: [[ 0.07598193  1.397718   -0.11633997 -2.13356   ]], Action: 1, Reward: 1.0, Next State: [[ 0.07598193  1.397718   -0.11633997 -2.13356   ]], Done: False\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 90, State: [[ 0.10393629  1.5937846  -0.15901117 -2.4597986 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10393629  1.5937846  -0.15901117 -2.4597986 ]], Done: False\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 49ms/step\n","Episode: 90, State: [[ 0.13581198  1.7898544  -0.20820715 -2.7967455 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13581198  1.7898544  -0.20820715 -2.7967455 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Episode: 90, State: [[ 0.17160907  1.9856871  -0.26414207 -3.1449223 ]], Action: 1, Reward: 1.0, Next State: [[ 0.17160907  1.9856871  -0.26414207 -3.1449223 ]], Done: True\n","Episode: 90, Total Reward: 10.0\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 48ms/step\n","Episode: 91, State: [[-0.00275253  0.22804289 -0.02631103 -0.27047977]], Action: 1, Reward: 1.0, Next State: [[-0.00275253  0.22804289 -0.02631103 -0.27047977]], Done: False\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Episode: 91, State: [[ 0.00180833  0.42353022 -0.03172062 -0.57134384]], Action: 1, Reward: 1.0, Next State: [[ 0.00180833  0.42353022 -0.03172062 -0.57134384]], Done: False\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 91, State: [[ 0.01027894  0.6190823  -0.0431475  -0.8738487 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01027894  0.6190823  -0.0431475  -0.8738487 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 91, State: [[ 0.02266058  0.8147635  -0.06062447 -1.1797787 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02266058  0.8147635  -0.06062447 -1.1797787 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 91, State: [[ 0.03895585  1.0106179  -0.08422004 -1.4908333 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03895585  1.0106179  -0.08422004 -1.4908333 ]], Done: False\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 91, State: [[ 0.05916821  1.206658   -0.11403672 -1.8085828 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05916821  1.206658   -0.11403672 -1.8085828 ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 91, State: [[ 0.08330137  1.4028523  -0.15020837 -2.1344168 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08330137  1.4028523  -0.15020837 -2.1344168 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 91, State: [[ 0.11135842  1.5991095  -0.19289671 -2.4694831 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11135842  1.5991095  -0.19289671 -2.4694831 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 91, State: [[ 0.1433406   1.7952617  -0.24228637 -2.8146152 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1433406   1.7952617  -0.24228637 -2.8146152 ]], Done: True\n","Episode: 91, Total Reward: 9.0\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 92, State: [[ 0.01956986  0.16557612 -0.03023704 -0.298151  ]], Action: 1, Reward: 1.0, Next State: [[ 0.01956986  0.16557612 -0.03023704 -0.298151  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 92, State: [[ 0.02288138  0.36111575 -0.03620006 -0.6002147 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02288138  0.36111575 -0.03620006 -0.6002147 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 92, State: [[ 0.03010369  0.5567249  -0.04820435 -0.90407676]], Action: 1, Reward: 1.0, Next State: [[ 0.03010369  0.5567249  -0.04820435 -0.90407676]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 92, State: [[ 0.04123819  0.7524654  -0.06628589 -1.211513  ]], Action: 1, Reward: 1.0, Next State: [[ 0.04123819  0.7524654  -0.06628589 -1.211513  ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 92, State: [[ 0.0562875   0.9483775  -0.09051615 -1.5242096 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0562875   0.9483775  -0.09051615 -1.5242096 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 92, State: [[ 0.07525505  1.1444684  -0.12100034 -1.8437172 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07525505  1.1444684  -0.12100034 -1.8437172 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 92, State: [[ 0.09814442  1.3406993  -0.15787469 -2.1713986 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09814442  1.3406993  -0.15787469 -2.1713986 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 92, State: [[ 0.1249584   1.5369698  -0.20130266 -2.5083656 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1249584   1.5369698  -0.20130266 -2.5083656 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 92, State: [[ 0.15569781  1.7331003  -0.25146997 -2.8554049 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15569781  1.7331003  -0.25146997 -2.8554049 ]], Done: True\n","Episode: 92, Total Reward: 9.0\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 93, State: [[-0.01879792  0.23285113 -0.02667897 -0.33326367]], Action: 1, Reward: 1.0, Next State: [[-0.01879792  0.23285113 -0.02667897 -0.33326367]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 93, State: [[-0.0141409   0.42834246 -0.03334424 -0.63423896]], Action: 1, Reward: 1.0, Next State: [[-0.0141409   0.42834246 -0.03334424 -0.63423896]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 93, State: [[-0.00557405  0.6239133  -0.04602902 -0.9372335 ]], Action: 1, Reward: 1.0, Next State: [[-0.00557405  0.6239133  -0.04602902 -0.9372335 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 93, State: [[ 0.00690422  0.81962466 -0.06477369 -1.2440175 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00690422  0.81962466 -0.06477369 -1.2440175 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 93, State: [[ 0.02329671  1.0155152  -0.08965404 -1.5562671 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02329671  1.0155152  -0.08965404 -1.5562671 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 93, State: [[ 0.04360702  1.2115895  -0.12077939 -1.8755203 ]], Action: 1, Reward: 1.0, Next State: [[ 0.04360702  1.2115895  -0.12077939 -1.8755203 ]], Done: False\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 93, State: [[ 0.0678388   1.4078048  -0.15828979 -2.2031221 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0678388   1.4078048  -0.15828979 -2.2031221 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 93, State: [[ 0.0959949   1.604056   -0.20235224 -2.5401618 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0959949   1.604056   -0.20235224 -2.5401618 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 93, State: [[ 0.12807602  1.8001567  -0.25315547 -2.8873975 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12807602  1.8001567  -0.25315547 -2.8873975 ]], Done: True\n","Episode: 93, Total Reward: 9.0\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 94, State: [[ 0.00805939  0.17003295  0.00975405 -0.26929167]], Action: 1, Reward: 1.0, Next State: [[ 0.00805939  0.17003295  0.00975405 -0.26929167]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 94, State: [[ 0.01146004  0.36501434  0.00436822 -0.55888224]], Action: 1, Reward: 1.0, Next State: [[ 0.01146004  0.36501434  0.00436822 -0.55888224]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Episode: 94, State: [[ 0.01876033  0.5600747  -0.00680943 -0.8501857 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01876033  0.5600747  -0.00680943 -0.8501857 ]], Done: False\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 94, State: [[ 0.02996183  0.75528884 -0.02381314 -1.1450021 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02996183  0.75528884 -0.02381314 -1.1450021 ]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Episode: 94, State: [[ 0.0450676   0.95071363 -0.04671318 -1.4450566 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0450676   0.95071363 -0.04671318 -1.4450566 ]], Done: False\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 54ms/step\n","Episode: 94, State: [[ 0.06408188  1.1463782  -0.07561431 -1.751962  ]], Action: 1, Reward: 1.0, Next State: [[ 0.06408188  1.1463782  -0.07561431 -1.751962  ]], Done: False\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 94, State: [[ 0.08700944  1.3422724  -0.11065355 -2.067173  ]], Action: 1, Reward: 1.0, Next State: [[ 0.08700944  1.3422724  -0.11065355 -2.067173  ]], Done: False\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 94, State: [[ 0.11385489  1.538333   -0.15199701 -2.3919313 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11385489  1.538333   -0.15199701 -2.3919313 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 46ms/step\n","Episode: 94, State: [[ 0.14462155  1.7344273  -0.19983564 -2.7271967 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14462155  1.7344273  -0.19983564 -2.7271967 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 57ms/step\n","Episode: 94, State: [[ 0.1793101   1.9303343  -0.25437957 -3.0735705 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1793101   1.9303343  -0.25437957 -3.0735705 ]], Done: True\n","Episode: 94, Total Reward: 10.0\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 95, State: [[ 0.01589267  0.18086971  0.01768102 -0.27585328]], Action: 1, Reward: 1.0, Next State: [[ 0.01589267  0.18086971  0.01768102 -0.27585328]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Episode: 95, State: [[ 0.01951006  0.37573498  0.01216396 -0.5629076 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01951006  0.37573498  0.01216396 -0.5629076 ]], Done: False\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 95, State: [[ 0.02702476  0.5706842   0.00090581 -0.85173357]], Action: 1, Reward: 1.0, Next State: [[ 0.02702476  0.5706842   0.00090581 -0.85173357]], Done: False\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 95, State: [[ 0.03843844  0.76579374 -0.01612886 -1.1441315 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03843844  0.76579374 -0.01612886 -1.1441315 ]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 39ms/step\n","Episode: 95, State: [[ 0.05375432  0.9611227  -0.03901149 -1.4418285 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05375432  0.9611227  -0.03901149 -1.4418285 ]], Done: False\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 95, State: [[ 0.07297677  1.1567026  -0.06784806 -1.7464417 ]], Action: 1, Reward: 1.0, Next State: [[ 0.07297677  1.1567026  -0.06784806 -1.7464417 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 95, State: [[ 0.09611083  1.352527   -0.1027769  -2.0594344 ]], Action: 1, Reward: 1.0, Next State: [[ 0.09611083  1.352527   -0.1027769  -2.0594344 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 95, State: [[ 0.12316137  1.5485371  -0.14396559 -2.3820615 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12316137  1.5485371  -0.14396559 -2.3820615 ]], Done: False\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 95, State: [[ 0.15413211  1.7446059  -0.19160682 -2.7153018 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15413211  1.7446059  -0.19160682 -2.7153018 ]], Done: False\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 95, State: [[ 0.18902422  1.9405192  -0.24591285 -3.0597823 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18902422  1.9405192  -0.24591285 -3.0597823 ]], Done: True\n","Episode: 95, Total Reward: 10.0\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 96, State: [[-0.02100203  0.15803565  0.03008129 -0.28655612]], Action: 1, Reward: 1.0, Next State: [[-0.02100203  0.15803565  0.03008129 -0.28655612]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 96, State: [[-0.01784131  0.35271597  0.02435017 -0.56960195]], Action: 1, Reward: 1.0, Next State: [[-0.01784131  0.35271597  0.02435017 -0.56960195]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 96, State: [[-0.010787    0.5474881   0.01295813 -0.85451525]], Action: 1, Reward: 1.0, Next State: [[-0.010787    0.5474881   0.01295813 -0.85451525]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 96, State: [[ 1.6276599e-04  7.4243104e-01 -4.1321777e-03 -1.1430956e+00]], Action: 1, Reward: 1.0, Next State: [[ 1.6276599e-04  7.4243104e-01 -4.1321777e-03 -1.1430956e+00]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 96, State: [[ 0.01501139  0.93760675 -0.02699409 -1.4370716 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01501139  0.93760675 -0.02699409 -1.4370716 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 96, State: [[ 0.03376352  1.1330509  -0.05573552 -1.7380662 ]], Action: 1, Reward: 1.0, Next State: [[ 0.03376352  1.1330509  -0.05573552 -1.7380662 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Episode: 96, State: [[ 0.05642454  1.3287619  -0.09049685 -2.0475545 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05642454  1.3287619  -0.09049685 -2.0475545 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 96, State: [[ 0.08299978  1.5246879  -0.13144794 -2.3668108 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08299978  1.5246879  -0.13144794 -2.3668108 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 96, State: [[ 0.11349353  1.7207106  -0.17878415 -2.6968427 ]], Action: 1, Reward: 1.0, Next State: [[ 0.11349353  1.7207106  -0.17878415 -2.6968427 ]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 46ms/step\n","Episode: 96, State: [[ 0.14790775  1.9166272  -0.232721   -3.0383162 ]], Action: 1, Reward: 1.0, Next State: [[ 0.14790775  1.9166272  -0.232721   -3.0383162 ]], Done: True\n","Episode: 96, Total Reward: 10.0\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 97, State: [[-0.00603852  0.20279205  0.03851233 -0.3023979 ]], Action: 1, Reward: 1.0, Next State: [[-0.00603852  0.20279205  0.03851233 -0.3023979 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 97, State: [[-0.00198268  0.39734456  0.03246437 -0.5826905 ]], Action: 1, Reward: 1.0, Next State: [[-0.00198268  0.39734456  0.03246437 -0.5826905 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 97, State: [[ 0.00596422  0.59199697  0.02081056 -0.8649724 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00596422  0.59199697  0.02081056 -0.8649724 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 97, State: [[ 0.01780416  0.7868296   0.00351111 -1.1510402 ]], Action: 1, Reward: 1.0, Next State: [[ 0.01780416  0.7868296   0.00351111 -1.1510402 ]], Done: False\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 97, State: [[ 0.03354075  0.9819056  -0.01950969 -1.44262   ]], Action: 1, Reward: 1.0, Next State: [[ 0.03354075  0.9819056  -0.01950969 -1.44262   ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 97, State: [[ 0.05317886  1.1772622  -0.04836209 -1.7413347 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05317886  1.1772622  -0.04836209 -1.7413347 ]], Done: False\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 97, State: [[ 0.0767241   1.3729001  -0.08318879 -2.0486615 ]], Action: 1, Reward: 1.0, Next State: [[ 0.0767241   1.3729001  -0.08318879 -2.0486615 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 97, State: [[ 0.10418211  1.5687705  -0.12416202 -2.3658803 ]], Action: 1, Reward: 1.0, Next State: [[ 0.10418211  1.5687705  -0.12416202 -2.3658803 ]], Done: False\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 97, State: [[ 0.13555752  1.7647586  -0.17147963 -2.6940093 ]], Action: 1, Reward: 1.0, Next State: [[ 0.13555752  1.7647586  -0.17147963 -2.6940093 ]], Done: False\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 97, State: [[ 0.17085269  1.9606663  -0.22535981 -3.033729  ]], Action: 1, Reward: 1.0, Next State: [[ 0.17085269  1.9606663  -0.22535981 -3.033729  ]], Done: True\n","Episode: 97, Total Reward: 10.0\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Episode: 98, State: [[-0.04982487  0.1591366  -0.0377994  -0.2831444 ]], Action: 1, Reward: 1.0, Next State: [[-0.04982487  0.1591366  -0.0377994  -0.2831444 ]], Done: False\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 98, State: [[-0.04664214  0.3547767  -0.04346228 -0.58750534]], Action: 1, Reward: 1.0, Next State: [[-0.04664214  0.3547767  -0.04346228 -0.58750534]], Done: False\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 41ms/step\n","Episode: 98, State: [[-0.03954661  0.55047953 -0.05521239 -0.89355624]], Action: 1, Reward: 1.0, Next State: [[-0.03954661  0.55047953 -0.05521239 -0.89355624]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 45ms/step\n","Episode: 98, State: [[-0.02853701  0.7463051  -0.07308351 -1.2030712 ]], Action: 1, Reward: 1.0, Next State: [[-0.02853701  0.7463051  -0.07308351 -1.2030712 ]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 42ms/step\n","Episode: 98, State: [[-0.01361091  0.94229186 -0.09714494 -1.517734  ]], Action: 1, Reward: 1.0, Next State: [[-0.01361091  0.94229186 -0.09714494 -1.517734  ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 50ms/step\n","Episode: 98, State: [[ 0.00523493  1.1384453  -0.12749963 -1.8390926 ]], Action: 1, Reward: 1.0, Next State: [[ 0.00523493  1.1384453  -0.12749963 -1.8390926 ]], Done: False\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 98, State: [[ 0.02800383  1.3347242  -0.16428147 -2.1685047 ]], Action: 1, Reward: 1.0, Next State: [[ 0.02800383  1.3347242  -0.16428147 -2.1685047 ]], Done: False\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Episode: 98, State: [[ 0.05469831  1.5310255  -0.20765156 -2.5070739 ]], Action: 1, Reward: 1.0, Next State: [[ 0.05469831  1.5310255  -0.20765156 -2.5070739 ]], Done: False\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 64ms/step\n","Episode: 98, State: [[ 0.08531883  1.7271665  -0.25779304 -2.8555768 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08531883  1.7271665  -0.25779304 -2.8555768 ]], Done: True\n","Episode: 98, Total Reward: 9.0\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Episode: 99, State: [[ 0.04584331  0.20274054 -0.01970414 -0.34831473]], Action: 1, Reward: 1.0, Next State: [[ 0.04584331  0.20274054 -0.01970414 -0.34831473]], Done: False\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Episode: 99, State: [[ 0.04989812  0.39813712 -0.02667043 -0.64714533]], Action: 1, Reward: 1.0, Next State: [[ 0.04989812  0.39813712 -0.02667043 -0.64714533]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Episode: 99, State: [[ 0.05786086  0.5936203  -0.03961334 -0.94810605]], Action: 1, Reward: 1.0, Next State: [[ 0.05786086  0.5936203  -0.03961334 -0.94810605]], Done: False\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Episode: 99, State: [[ 0.06973327  0.7892526  -0.05857546 -1.2529676 ]], Action: 1, Reward: 1.0, Next State: [[ 0.06973327  0.7892526  -0.05857546 -1.2529676 ]], Done: False\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 99, State: [[ 0.08551832  0.9850739  -0.08363481 -1.5634071 ]], Action: 1, Reward: 1.0, Next State: [[ 0.08551832  0.9850739  -0.08363481 -1.5634071 ]], Done: False\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Episode: 99, State: [[ 0.1052198   1.1810905  -0.11490295 -1.8809642 ]], Action: 1, Reward: 1.0, Next State: [[ 0.1052198   1.1810905  -0.11490295 -1.8809642 ]], Done: False\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 99, State: [[ 0.12884161  1.3772614  -0.15252224 -2.2069874 ]], Action: 1, Reward: 1.0, Next State: [[ 0.12884161  1.3772614  -0.15252224 -2.2069874 ]], Done: False\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Episode: 99, State: [[ 0.15638684  1.5734836  -0.19666198 -2.5425715 ]], Action: 1, Reward: 1.0, Next State: [[ 0.15638684  1.5734836  -0.19666198 -2.5425715 ]], Done: False\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Episode: 99, State: [[ 0.18785651  1.7695736  -0.24751341 -2.8884835 ]], Action: 1, Reward: 1.0, Next State: [[ 0.18785651  1.7695736  -0.24751341 -2.8884835 ]], Done: True\n","Episode: 99, Total Reward: 9.0\n"]}],"source":["import gym\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","# 환경 초기화\n","env = gym.make('CartPole-v1')\n","state_size = env.observation_space.shape[0]\n","action_size = env.action_space.n\n","\n","# 환경 모델\n","model = Sequential()\n","model.add(Dense(24, input_dim=state_size, activation='relu'))\n","model.add(Dense(24, activation='relu'))\n","model.add(Dense(action_size, activation='linear'))\n","model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n","\n","# 모델 기반 강화 학습 수행\n","def train_model():\n","    for episode in range(100):  # 에피소드 수\n","        state = env.reset()\n","        state = np.reshape(state, [1, state_size])\n","        done = False\n","        total_reward = 0\n","\n","        while not done:\n","            # 행동 선택\n","            action = np.argmax(model.predict(state)[0])\n","            next_state, reward, done, _ = env.step(action)\n","            next_state = np.reshape(next_state, [1, state_size])\n","            total_reward += reward\n","\n","            # 모델 업데이트\n","            target = (reward + 0.99 * np.max(model.predict(next_state)[0])) * (1 - done)\n","            target_f = model.predict(state)\n","            target_f[0][action] = target\n","            model.fit(state, target_f, epochs=1, verbose=0)\n","\n","            state = next_state\n","\n","            # 실행 중 값 확인\n","            print(f\"Episode: {episode}, State: {state}, Action: {action}, Reward: {reward}, Next State: {next_state}, Done: {done}\")\n","\n","        # 에피소드별 총 보상 출력\n","        print(f\"Episode: {episode}, Total Reward: {total_reward}\")\n","\n","# 모델 학습\n","train_model()"]}]}