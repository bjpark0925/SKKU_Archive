{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCzvvuqPhdZG","outputId":"4a83f122-2cfb-436b-faec-ebc5b3ba9032"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 로딩...\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 1s 0us/step\n","25000 훈련 시퀀스\n","25000 테스트 시퀀스\n","시퀀스 패딩 (samples x time)\n","input_train 크기: (25000, 500)\n","input_test 크기: (25000, 500)\n","Epoch 1/10\n","157/157 [==============================] - 26s 160ms/step - loss: 0.5625 - acc: 0.7071 - val_loss: 0.4402 - val_acc: 0.8064\n","Epoch 2/10\n","157/157 [==============================] - 25s 158ms/step - loss: 0.3760 - acc: 0.8378 - val_loss: 0.3942 - val_acc: 0.8386\n","Epoch 3/10\n","157/157 [==============================] - 25s 158ms/step - loss: 0.3032 - acc: 0.8777 - val_loss: 0.3616 - val_acc: 0.8520\n","Epoch 4/10\n","157/157 [==============================] - 25s 158ms/step - loss: 0.2442 - acc: 0.9071 - val_loss: 0.3943 - val_acc: 0.8386\n","Epoch 5/10\n","157/157 [==============================] - 25s 157ms/step - loss: 0.1959 - acc: 0.9272 - val_loss: 0.3595 - val_acc: 0.8664\n","Epoch 6/10\n","157/157 [==============================] - 24s 150ms/step - loss: 0.1552 - acc: 0.9444 - val_loss: 0.4319 - val_acc: 0.8202\n","Epoch 7/10\n","157/157 [==============================] - 25s 156ms/step - loss: 0.1147 - acc: 0.9613 - val_loss: 0.4200 - val_acc: 0.8496\n","Epoch 8/10\n","157/157 [==============================] - 25s 157ms/step - loss: 0.0848 - acc: 0.9722 - val_loss: 0.4603 - val_acc: 0.8504\n","Epoch 9/10\n","157/157 [==============================] - 25s 157ms/step - loss: 0.0702 - acc: 0.9785 - val_loss: 0.6394 - val_acc: 0.7680\n","Epoch 10/10\n","157/157 [==============================] - 25s 158ms/step - loss: 0.0471 - acc: 0.9863 - val_loss: 1.0350 - val_acc: 0.6884\n","782/782 [==============================] - 21s 27ms/step - loss: 0.9888 - acc: 0.6938\n","테스트 손실: 0.9888033866882324\n","테스트 정확도: 0.6938400268554688\n"]}],"source":["from keras.datasets import imdb\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Embedding, SimpleRNN, Dense\n","\n","# IMDB 데이터셋 로드\n","# num_words는 데이터에서 가장 자주 등장하는 단어 10000개만 사용하겠다는 의미입니다.\n","max_features = 10000\n","maxlen = 500  # 리뷰를 500 단어 이후는 잘라냅니다.\n","batch_size = 32\n","\n","print('데이터 로딩...')\n","(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","print(len(input_train), '훈련 시퀀스')\n","print(len(input_test), '테스트 시퀀스')\n","\n","print('시퀀스 패딩 (samples x time)')\n","input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n","input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n","\n","print('input_train 크기:', input_train.shape)\n","print('input_test 크기:', input_test.shape)\n","\n","# RNN 모델 구축\n","model = Sequential()\n","model.add(Embedding(max_features, 32))\n","model.add(SimpleRNN(32))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 모델 컴파일\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","\n","# 모델 훈련\n","history = model.fit(input_train, y_train,\n","                    epochs=10,\n","                    batch_size=128,\n","                    validation_split=0.2)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(input_test, y_test)\n","print('테스트 손실:', test_loss)\n","print('테스트 정확도:', test_acc)"]},{"cell_type":"code","source":["# IMDB 데이터셋의 word_index 가져오기\n","word_index = imdb.get_word_index()\n","\n","# 새로운 리뷰 텍스트\n","new_review = 'This movie was fantastic! I really loved it and would watch it again because it was amazingly great'\n","\n","# 텍스트를 단어 인덱스의 시퀀스로 변환하는 함수\n","def encode_review(text):\n","    tokens = text.lower().split()\n","    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n","    return sequence.pad_sequences([tokens], maxlen=maxlen)\n","\n","# 새로운 리뷰를 시퀀스로 인코딩\n","encoded_review = encode_review(new_review)\n","\n","# 모델을 사용하여 새로운 리뷰의 감성 예측\n","prediction = model.predict(encoded_review)\n","\n","# 결과 출력\n","print('Review sentiment (1 for positive and 0 for negative):', prediction[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4DI7DvsJqYM","outputId":"a7afd86b-f571-423b-ed3c-2b914ca470ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n","1/1 [==============================] - 0s 204ms/step\n","Review sentiment (1 for positive and 0 for negative): 0.93300307\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5-PPlNzsKAPX"},"execution_count":null,"outputs":[]}]}